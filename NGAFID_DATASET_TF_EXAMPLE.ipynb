{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyang0129/NGAFIDDATASET/blob/main/NGAFID_DATASET_TF_EXAMPLE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NBLjv7UgsWd"
      },
      "source": [
        "# INSTALL PREREQ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0X2aMD0lLrg",
        "outputId": "47c14038-8fea-45c0-f642-a62586811ac4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'NGAFIDDATASET' already exists and is not an empty directory.\n",
            "Already on 'main'\n",
            "Your branch is up to date with 'origin/main'.\n",
            "HEAD is now at a2d7377 Merge remote-tracking branch 'origin/main'\n",
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 3 (delta 2), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (3/3), done.\n",
            "From https://github.com/hyang0129/NGAFIDDATASET\n",
            "   a2d7377..68b7eac  main       -> origin/main\n",
            "Updating a2d7377..68b7eac\n",
            "Fast-forward\n",
            " NGAFID_DATASET_MINIROCKET_EXAMPLE.ipynb | 1906 \u001b[32m+++++++\u001b[m\u001b[31m------------------------\u001b[m\n",
            " 1 file changed, 426 insertions(+), 1480 deletions(-)\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/hyang0129/NGAFIDDATASET.git\n",
        "\n",
        "!(cd NGAFIDDATASET ; git checkout main; git reset --hard HEAD; git pull)\n",
        "!(cd NGAFIDDATASET ; pip install -r requirements.txt -q)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jb948fwpgvDN"
      },
      "source": [
        "# IMPORT DEPENDENCIES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BscNhNpszOl3"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "027FHavVxd-g"
      },
      "outputs": [],
      "source": [
        "import sys \n",
        "sys.path.append('/content/NGAFIDDATASET')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8s4eIqhm1AiX",
        "outputId": "64a4c97c-2cb7-4140-fe86-c90395dc3b11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ],
      "source": [
        "from tqdm.autonotebook import tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgLDpCrBxkiP",
        "outputId": "5572b7d6-4d89-40df-8874-0dd342296adb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TPU address is grpc://10.51.174.106:8470\n",
            "Running on TPU  grpc://10.51.174.106:8470\n",
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.51.174.106:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.51.174.106:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "REPLICAS:  8\n"
          ]
        }
      ],
      "source": [
        "%autoreload\n",
        "from ngafiddataset.dataset.dataset import NGAFID_Dataset_Manager\n",
        "from ngafiddataset.dataset.utils import to_dict_of_list\n",
        "from ngafiddataset.utils import connect_to_tpu\n",
        "import pandas as pd \n",
        "\n",
        "\n",
        "strategy = connect_to_tpu()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfrR0ZDrg2N8"
      },
      "source": [
        "# DEFINE MODEL FN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "D6IBWF6lg3gn"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "tfk = tf.keras\n",
        "tfkl = tf.keras.layers\n",
        "\n",
        "class Classifier_INCEPTION:\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_shape,\n",
        "        nb_classes,\n",
        "        build=True,\n",
        "        batch_size=64,\n",
        "        nb_filters=32,\n",
        "        use_residual=True,\n",
        "        use_bottleneck=True,\n",
        "        depth=6,\n",
        "        kernel_size=41,\n",
        "        nb_epochs=1500,\n",
        "        two_output = False, \n",
        "        mode = None\n",
        "    ):\n",
        "\n",
        "        self.nb_filters = nb_filters\n",
        "        self.use_residual = use_residual\n",
        "        self.use_bottleneck = use_bottleneck\n",
        "        self.depth = depth\n",
        "        self.kernel_size = kernel_size - 1\n",
        "        self.callbacks = None\n",
        "        self.batch_size = batch_size\n",
        "        self.bottleneck_size = 32\n",
        "        self.nb_epochs = nb_epochs\n",
        "        self.two_output = two_output \n",
        "        self.mode = mode \n",
        "\n",
        "        if build is True:\n",
        "            self.model = self.build_model(input_shape, nb_classes)\n",
        "\n",
        "    def _inception_module(self, input_tensor, stride=1, activation=\"linear\"):\n",
        "\n",
        "        if self.use_bottleneck and int(input_tensor.shape[-1]) > 1:\n",
        "            input_inception = tf.keras.layers.Conv1D(\n",
        "                filters=self.bottleneck_size, kernel_size=1, padding=\"same\", activation=activation, use_bias=False\n",
        "            )(input_tensor)\n",
        "        else:\n",
        "            input_inception = input_tensor\n",
        "\n",
        "        # kernel_size_s = [3, 5, 8, 11, 17]\n",
        "        kernel_size_s = [self.kernel_size // (2 ** i) for i in range(3)]\n",
        "\n",
        "        conv_list = []\n",
        "\n",
        "        for i in range(len(kernel_size_s)):\n",
        "            conv_list.append(\n",
        "                tf.keras.layers.Conv1D(\n",
        "                    filters=self.nb_filters,\n",
        "                    kernel_size=kernel_size_s[i],\n",
        "                    strides=stride,\n",
        "                    padding=\"same\",\n",
        "                    activation=activation,\n",
        "                    use_bias=False,\n",
        "                )(input_inception)\n",
        "            )\n",
        "\n",
        "        max_pool_1 = tf.keras.layers.MaxPool1D(pool_size=3, strides=stride, padding=\"same\")(input_tensor)\n",
        "\n",
        "        conv_6 = tf.keras.layers.Conv1D(\n",
        "            filters=self.nb_filters, kernel_size=1, padding=\"same\", activation=activation, use_bias=False\n",
        "        )(max_pool_1)\n",
        "\n",
        "        conv_list.append(conv_6)\n",
        "\n",
        "        x = tf.keras.layers.Concatenate(axis=2)(conv_list)\n",
        "        x = tf.keras.layers.BatchNormalization()(x)\n",
        "        x = tf.keras.layers.Activation(activation=\"relu\")(x)\n",
        "        return x\n",
        "\n",
        "    def _shortcut_layer(self, input_tensor, out_tensor):\n",
        "        shortcut_y = tf.keras.layers.Conv1D(\n",
        "            filters=int(out_tensor.shape[-1]), kernel_size=1, padding=\"same\", use_bias=False\n",
        "        )(input_tensor)\n",
        "        shortcut_y = tf.keras.layers.BatchNormalization()(shortcut_y)\n",
        "\n",
        "        x = tf.keras.layers.Add()([shortcut_y, out_tensor])\n",
        "        x = tf.keras.layers.Activation(\"relu\")(x)\n",
        "        return x\n",
        "\n",
        "    def build_model(self, input_shape, nb_classes):\n",
        "        input_layer = tf.keras.layers.Input(input_shape, name = 'data')\n",
        "\n",
        "        x = input_layer\n",
        "        input_res = input_layer\n",
        "\n",
        "        for d in range(self.depth):\n",
        "\n",
        "            x = self._inception_module(x)\n",
        "\n",
        "            if self.use_residual and d % 3 == 2:\n",
        "                x = self._shortcut_layer(input_res, x)\n",
        "                input_res = x\n",
        "\n",
        "        gap_layer = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
        "\n",
        "        \n",
        "        outputs = [] \n",
        "\n",
        "        outputs.append(tf.keras.layers.Dense(nb_classes, activation=\"softmax\", name='target_class')(gap_layer))\n",
        "\n",
        "        if self.two_output: \n",
        "            outputs.append(tf.keras.layers.Dense(1, activation=\"sigmoid\", name='before_after')(gap_layer))\n",
        "        \n",
        "        \n",
        "        if self.mode == 'before_after':\n",
        "            outputs = [] \n",
        "            outputs.append(tf.keras.layers.Dense(1, activation=\"sigmoid\", name='before_after')(gap_layer))\n",
        "\n",
        "        model = tf.keras.models.Model(inputs=input_layer, outputs=outputs)\n",
        "\n",
        "        return model\n",
        "\n",
        "    def get_kernel_model(self):\n",
        "        '''\n",
        "        Get a model whose output is just the global average pooling layer.\n",
        "\n",
        "        Returns:\n",
        "\n",
        "        '''\n",
        "\n",
        "        return tf.keras.Model(self.model.layers[0].input, self.model.layers[-2].output)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBAETchjmf-W",
        "outputId": "1b1fc00f-c7c2-468a-ecdf-3c071a6dcd45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " data (InputLayer)              [(None, 4096, 23)]   0           []                               \n",
            "                                                                                                  \n",
            " sequential_4 (Sequential)      (None, 512)          10153344    ['data[0][0]']                   \n",
            "                                                                                                  \n",
            " target_class (Dense)           (None, 2)            1026        ['sequential_4[0][0]']           \n",
            "                                                                                                  \n",
            " before_after (Dense)           (None, 1)            513         ['sequential_4[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 10,154,883\n",
            "Trainable params: 10,154,883\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "def point_wise_feed_forward_network(d_model, dff):\n",
        "  return tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
        "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
        "  ])\n",
        "\n",
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "  \"\"\"Calculate the attention weights.\n",
        "  q, k, v must have matching leading dimensions.\n",
        "  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
        "  The mask has different shapes depending on its type(padding or look ahead)\n",
        "  but it must be broadcastable for addition.\n",
        "\n",
        "  Args:\n",
        "    q: query shape == (..., seq_len_q, depth)\n",
        "    k: key shape == (..., seq_len_k, depth)\n",
        "    v: value shape == (..., seq_len_v, depth_v)\n",
        "    mask: Float tensor with shape broadcastable\n",
        "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
        "\n",
        "  Returns:\n",
        "    output, attention_weights\n",
        "  \"\"\"\n",
        "\n",
        "  matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "  # scale matmul_qk\n",
        "  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "\n",
        "  # add the mask to the scaled tensor.\n",
        "  if mask is not None:\n",
        "    scaled_attention_logits += (mask * -1e9)\n",
        "\n",
        "  # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
        "  # add up to 1.\n",
        "  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "  output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
        "\n",
        "  return output, attention_weights\n",
        "\n",
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads):\n",
        "    super(MultiHeadAttention, self).__init__()\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "\n",
        "    assert d_model % self.num_heads == 0\n",
        "\n",
        "    self.depth = d_model // self.num_heads\n",
        "\n",
        "    self.wq = tf.keras.layers.Dense(d_model)\n",
        "    self.wk = tf.keras.layers.Dense(d_model)\n",
        "    self.wv = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "  def split_heads(self, x, batch_size):\n",
        "    \"\"\"Split the last dimension into (num_heads, depth).\n",
        "    Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
        "    \"\"\"\n",
        "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "  def call(self, v, k, q, mask):\n",
        "    batch_size = tf.shape(q)[0]\n",
        "\n",
        "    q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
        "    k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
        "    v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
        "\n",
        "    q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
        "    k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
        "    v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
        "\n",
        "    # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
        "    # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
        "    scaled_attention, attention_weights = scaled_dot_product_attention(\n",
        "        q, k, v, mask)\n",
        "\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
        "\n",
        "    concat_attention = tf.reshape(scaled_attention,\n",
        "                                  (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "    output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "    return output, attention_weights\n",
        "\n",
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "    super(EncoderLayer, self).__init__()\n",
        "\n",
        "    self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "  def call(self, x, training, mask = None):\n",
        "\n",
        "    attn_output, self.attention_values = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
        "    attn_output = self.dropout1(attn_output, training=training)\n",
        "    out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "    ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
        "    ffn_output = self.dropout2(ffn_output, training=training)\n",
        "    out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "    return out2\n",
        "\n",
        "def get_angles(pos, i, d_model):\n",
        "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
        "    return pos * angle_rates\n",
        "\n",
        "def positional_encoding(position, d_model):\n",
        "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
        "                            np.arange(d_model)[np.newaxis, :],\n",
        "                            d_model)\n",
        "\n",
        "    # apply sin to even indices in the array; 2i\n",
        "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "\n",
        "    # apply cos to odd indices in the array; 2i+1\n",
        "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    pos_encoding = angle_rads[np.newaxis, ...]\n",
        "\n",
        "    return tf.cast(pos_encoding, dtype=tf.float32)\n",
        "\n",
        "class PositionalEncoding(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, maximum_position_encoding = 1000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "\n",
        "        self.pos_encoding = positional_encoding(maximum_position_encoding,\n",
        "                                        512)\n",
        "\n",
        "    def call(self, x):\n",
        "\n",
        "        seq_len = tf.shape(x)[1]\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "        return x \n",
        "\n",
        "def get_mhsa_model(nbclass = 2, SHAPE = (4096, 23), mode = 'before_after'):\n",
        "    # I realize that I did not include a positional embedding, but its too late now. Maybe a future paper could address this? \n",
        "    d = 512\n",
        "    ff = 1024\n",
        "    model =  tfk.Sequential([tf.keras.Input(shape = SHAPE),\n",
        "                                            tfkl.Conv1D(128, 7, strides = 1, padding='same', activation='relu'),\n",
        "                                            # tfkl.BatchNormalization(),\n",
        "                                            tfkl.Conv1D(128, 7, strides = 2, padding='same', activation='relu'),\n",
        "                                            # tfkl.BatchNormalization(),\n",
        "                                            tfkl.Conv1D(256, 7, strides = 1, padding='same', activation='relu'),\n",
        "                                            # tfkl.BatchNormalization(),\n",
        "                                            tfkl.Conv1D(256, 7, strides = 2, padding='same', activation='relu'),\n",
        "                                            # tfkl.BatchNormalization(),\n",
        "                                            # tfkl.Conv1D(512, 7, strides = 1, padding='same', activation='relu'),\n",
        "                                            tfkl.Conv1D(512, 7, strides = 2, padding='same', activation='relu'),\n",
        "                                            # tfkl.Conv1D(768, 7, strides = 1, padding='same', activation='relu'),\n",
        "                                            # tfkl.BatchNormalization(),\n",
        "                                            EncoderLayer(d_model=d, num_heads=8, dff=ff),\n",
        "                                            EncoderLayer(d_model=d, num_heads=8, dff=ff),\n",
        "                                            EncoderLayer(d_model=d, num_heads=8, dff=ff),\n",
        "                                            EncoderLayer(d_model=d, num_heads=8, dff=ff),\n",
        "                                            \n",
        "                                            tf.keras.layers.GlobalAveragePooling1D(),\n",
        "                                            # tfkl.Dense(nbclass, activation='softmax'),\n",
        "    ])\n",
        "\n",
        "\n",
        "    input = tf.keras.Input(shape = SHAPE, name = 'data')\n",
        "\n",
        "    x = model(input)\n",
        "\n",
        "    output = []\n",
        "    if mode == 'before_after': \n",
        "        output =  tfkl.Dense(1, activation='sigmoid', name = 'before_after')(x)\n",
        "    elif mode == 'both': \n",
        "        output.append(tf.keras.layers.Dense(nbclass, activation=\"softmax\", name='target_class')(x))\n",
        "        output.append(tfkl.Dense(1, activation='sigmoid', name = 'before_after')(x))\n",
        "    elif mode == 'classes': \n",
        "        output.append(tf.keras.layers.Dense(nbclass, activation=\"softmax\", name='target_class')(x))\n",
        "\n",
        "    fun_model = tf.keras.Model(input, output)\n",
        "\n",
        "    return fun_model\n",
        "\n",
        "def get_mhsa_model_pe():\n",
        "    # I realize that I did not include a positional embedding, but its too late now. Maybe a future paper could address this? \n",
        "\n",
        "    model =  tfk.Sequential([tf.keras.Input(shape = SHAPE),\n",
        "                                            tfkl.Conv1D(128, 7, strides = 1, padding='same', activation='relu'),\n",
        "                                            tfkl.BatchNormalization(),\n",
        "                                            tfkl.Conv1D(128, 7, strides = 2, padding='same', activation='relu'),\n",
        "                                            tfkl.BatchNormalization(),\n",
        "                                            tfkl.Conv1D(256, 3, strides = 1, padding='same', activation='relu'),\n",
        "                                            tfkl.BatchNormalization(),\n",
        "                                            tfkl.Conv1D(256, 7, strides = 2, padding='same', activation='relu'),\n",
        "                                            tfkl.BatchNormalization(),\n",
        "                                            tfkl.Conv1D(512, 7, strides = 2, padding='same', activation='relu'),\n",
        "                                            tfkl.BatchNormalization(),\n",
        "                                            # tfkl.Conv1D(512, 7, strides = 2, padding='same', activation='relu'),\n",
        "                                            # tfkl.Conv1D(512, 7, strides = 2, padding='same', activation='relu'),\n",
        "                                            PositionalEncoding(),\n",
        "                                            EncoderLayer(d_model=512, num_heads=8, dff=512),\n",
        "                                            EncoderLayer(d_model=512, num_heads=8, dff=512),\n",
        "                                            EncoderLayer(d_model=512, num_heads=8, dff=512),\n",
        "                                            EncoderLayer(d_model=512, num_heads=8, dff=512),\n",
        "                                            # tfkl.Lambda(lambda x : x[:, 0, :]),\n",
        "                                            tf.keras.layers.GlobalAveragePooling1D(),\n",
        "                                            tfkl.Dense(1, activation='sigmoid'),\n",
        "    ])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "model = get_mhsa_model(mode = 'both')\n",
        "model.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jk4zIneNgwzO"
      },
      "source": [
        "# SETUP DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "17cd17ddd64247be8604b1a634d864d3",
            "4daf288c958e4a14a8875d10fb0990f8",
            "733144cac2704989a3900131fa31a612",
            "ea445d2e6ac24209874559c87f04f87b",
            "3cf5bf042a304ef38c3d95af0dae98d6",
            "dc5f065deac34a3089870ef8ce6c5520",
            "730d73e86352458d985ca4e11e2e52d5",
            "64f8f635e54748dfada9321fc315e89c",
            "67ebbe7d85db455f8a87a1109e2dd6d3",
            "696a4a4233074dd09fe98e7a17bb0d1e",
            "7774690c444047c6a76733aa02f14621"
          ]
        },
        "id": "kDYNIjFdtMEb",
        "outputId": "19ca9c64-328b-4fd8-c8a4-f266bc02c2f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-06-08 21:44:59.099 | INFO     | ngafiddataset.dataset.dataset:download:39 - Extracting File\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/11446 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "17cd17ddd64247be8604b1a634d864d3"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "dm = NGAFID_Dataset_Manager('2days')\n",
        "df = pd.read_csv('/content/2days/flight_header.csv')\n",
        "\n",
        "dm.data_dict =  dm.construct_data_dictionary(numpy=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMlBnOGQ43jv",
        "outputId": "1b0bb464-3e5a-4901-bcb7-9a81e42db410"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "number_classes = len(dm.flight_header_df['class'].unique())\n",
        "number_classes\n",
        "\n",
        "number_hierarchies = len(dm.flight_header_df['hclass'].unique())\n",
        "number_hierarchies\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUnni6illOea"
      },
      "source": [
        "# DEFINE TASK "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "MW93Quq24d3f"
      },
      "outputs": [],
      "source": [
        "# mode = 'before_after'\n",
        "# mode = 'hierarchy_basic'\n",
        "mode = 'both'\n",
        "# mode = 'classes'\n",
        "\n",
        "# DETERMINE MODEL STRUCTURE BASED ON OUTPUTS \n",
        "two_output = False\n",
        "if mode == 'before_after': \n",
        "    nb_classes = 1\n",
        "elif mode == 'hierarchy_basic':\n",
        "    nb_classes = number_hierarchies + 1\n",
        "    two_output = True \n",
        "elif mode == 'both':\n",
        "    two_output = True\n",
        "    nb_classes = number_classes+1\n",
        "else:\n",
        "    nb_classes = number_classes+1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l34Mz7tMlQri"
      },
      "source": [
        "# TRAIN MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "HM5qBjAXbLp8"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Saver(tf.keras.callbacks.Callback): \n",
        "    \n",
        "    def __init__(self, model_name): \n",
        "        super().__init__()\n",
        "        self.model_name = model_name \n",
        "        # self.bucket = bucket \n",
        "        # self.fs = gcsfs.GCSFileSystem(project='tpu-44747', token = 'gckey.json')\n",
        "        self.start = 5\n",
        "        self.best = 0\n",
        "    \n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if epoch > self.start: \n",
        "            pass\n",
        "        \n",
        "        metric = 'val_loss'\n",
        "\n",
        "        try: \n",
        "            if logs.get(metric) >= 0.85 and logs.get(metric) > self.best: \n",
        "                print('saving good model')\n",
        "                lpath = self.model_name + '.h5'\n",
        "                self.model.save(lpath, include_optimizer=False)\n",
        "                self.best = logs.get(metric)\n",
        "        except Exception as E:\n",
        "            print('encountered some error in model saving process')\n",
        "            print(E)\n",
        "            pass \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "61448d8920c34a4da4eef6762526d81a",
            "e670557cec5d4ce484cdc5b769406320",
            "2c4626cb3c1249d4869cca9f3d7a71e0",
            "37a136e3b89e42e7b3dd793afaf2b07f",
            "74f9aba46a3e4b40959d863d8a68aab6",
            "77d1972762c04187b67975e9774591ea",
            "a98e9cedb63e4278952e471862734ae4",
            "64cebde0e00643b2aa1a971d8fd5a856",
            "9dca06eb92eb42afac8da02646aeed9f",
            "748fdf920c634b58b2f92434db9ed5db",
            "6f7eee80fea64072b3cf00fc9e76079e"
          ]
        },
        "id": "RM8oXegXiZvk",
        "outputId": "1fe24621-79a6-4fe1-bcfd-0d2821a63c3c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "61448d8920c34a4da4eef6762526d81a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.9921 - target_class_loss: 2.2743 - before_after_loss: 0.7178 - target_class_multi_acc: 0.3891 - before_after_single_acc: 0.5248\n",
            "Epoch 1: val_loss improved from inf to 3.02834, saving model to best.h5\n",
            "100/100 [==============================] - 45s 198ms/step - loss: 2.9921 - target_class_loss: 2.2743 - before_after_loss: 0.7178 - target_class_multi_acc: 0.3891 - before_after_single_acc: 0.5248 - val_loss: 3.0283 - val_target_class_loss: 2.3316 - val_before_after_loss: 0.6968 - val_target_class_multi_acc: 0.4738 - val_before_after_single_acc: 0.5129\n",
            "Epoch 2/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.5746 - target_class_loss: 1.9015 - before_after_loss: 0.6731 - target_class_multi_acc: 0.5034 - before_after_single_acc: 0.5842\n",
            "Epoch 2: val_loss improved from 3.02834 to 2.92766, saving model to best.h5\n",
            "100/100 [==============================] - 15s 155ms/step - loss: 2.5746 - target_class_loss: 1.9015 - before_after_loss: 0.6731 - target_class_multi_acc: 0.5034 - before_after_single_acc: 0.5842 - val_loss: 2.9277 - val_target_class_loss: 2.0229 - val_before_after_loss: 0.9047 - val_target_class_multi_acc: 0.5051 - val_before_after_single_acc: 0.5078\n",
            "Epoch 3/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.5027 - target_class_loss: 1.8357 - before_after_loss: 0.6670 - target_class_multi_acc: 0.5082 - before_after_single_acc: 0.5934\n",
            "Epoch 3: val_loss improved from 2.92766 to 2.58747, saving model to best.h5\n",
            "100/100 [==============================] - 15s 153ms/step - loss: 2.5027 - target_class_loss: 1.8357 - before_after_loss: 0.6670 - target_class_multi_acc: 0.5082 - before_after_single_acc: 0.5934 - val_loss: 2.5875 - val_target_class_loss: 1.9045 - val_before_after_loss: 0.6830 - val_target_class_multi_acc: 0.5023 - val_before_after_single_acc: 0.5565\n",
            "Epoch 4/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.4674 - target_class_loss: 1.8109 - before_after_loss: 0.6565 - target_class_multi_acc: 0.5087 - before_after_single_acc: 0.6102\n",
            "Epoch 4: val_loss did not improve from 2.58747\n",
            "100/100 [==============================] - 15s 149ms/step - loss: 2.4674 - target_class_loss: 1.8109 - before_after_loss: 0.6565 - target_class_multi_acc: 0.5087 - before_after_single_acc: 0.6102 - val_loss: 2.6890 - val_target_class_loss: 1.9824 - val_before_after_loss: 0.7066 - val_target_class_multi_acc: 0.4145 - val_before_after_single_acc: 0.4899\n",
            "Epoch 5/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.4132 - target_class_loss: 1.7604 - before_after_loss: 0.6528 - target_class_multi_acc: 0.5118 - before_after_single_acc: 0.6176\n",
            "Epoch 5: val_loss did not improve from 2.58747\n",
            "100/100 [==============================] - 15s 153ms/step - loss: 2.4132 - target_class_loss: 1.7604 - before_after_loss: 0.6528 - target_class_multi_acc: 0.5118 - before_after_single_acc: 0.6176 - val_loss: 2.6130 - val_target_class_loss: 1.8974 - val_before_after_loss: 0.7155 - val_target_class_multi_acc: 0.5124 - val_before_after_single_acc: 0.5253\n",
            "Epoch 6/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.3774 - target_class_loss: 1.7308 - before_after_loss: 0.6466 - target_class_multi_acc: 0.5142 - before_after_single_acc: 0.6237\n",
            "Epoch 6: val_loss did not improve from 2.58747\n",
            "100/100 [==============================] - 15s 149ms/step - loss: 2.3774 - target_class_loss: 1.7308 - before_after_loss: 0.6466 - target_class_multi_acc: 0.5142 - before_after_single_acc: 0.6237 - val_loss: 2.6024 - val_target_class_loss: 1.8546 - val_before_after_loss: 0.7478 - val_target_class_multi_acc: 0.4995 - val_before_after_single_acc: 0.5404\n",
            "Epoch 7/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.3933 - target_class_loss: 1.7490 - before_after_loss: 0.6443 - target_class_multi_acc: 0.5145 - before_after_single_acc: 0.6251\n",
            "Epoch 7: val_loss did not improve from 2.58747\n",
            "100/100 [==============================] - 15s 149ms/step - loss: 2.3933 - target_class_loss: 1.7490 - before_after_loss: 0.6443 - target_class_multi_acc: 0.5145 - before_after_single_acc: 0.6251 - val_loss: 2.7827 - val_target_class_loss: 1.9078 - val_before_after_loss: 0.8749 - val_target_class_multi_acc: 0.5129 - val_before_after_single_acc: 0.5299\n",
            "Epoch 8/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.3841 - target_class_loss: 1.7420 - before_after_loss: 0.6421 - target_class_multi_acc: 0.5173 - before_after_single_acc: 0.6319\n",
            "Epoch 8: val_loss did not improve from 2.58747\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 2.3841 - target_class_loss: 1.7420 - before_after_loss: 0.6421 - target_class_multi_acc: 0.5173 - before_after_single_acc: 0.6319 - val_loss: 2.8157 - val_target_class_loss: 2.0163 - val_before_after_loss: 0.7994 - val_target_class_multi_acc: 0.2353 - val_before_after_single_acc: 0.4913\n",
            "Epoch 9/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.3974 - target_class_loss: 1.7608 - before_after_loss: 0.6365 - target_class_multi_acc: 0.5096 - before_after_single_acc: 0.6333\n",
            "Epoch 9: val_loss did not improve from 2.58747\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 2.3974 - target_class_loss: 1.7608 - before_after_loss: 0.6365 - target_class_multi_acc: 0.5096 - before_after_single_acc: 0.6333 - val_loss: 2.9939 - val_target_class_loss: 1.9924 - val_before_after_loss: 1.0015 - val_target_class_multi_acc: 0.5005 - val_before_after_single_acc: 0.5184\n",
            "Epoch 10/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.3294 - target_class_loss: 1.7046 - before_after_loss: 0.6248 - target_class_multi_acc: 0.5209 - before_after_single_acc: 0.6508\n",
            "Epoch 10: val_loss did not improve from 2.58747\n",
            "100/100 [==============================] - 15s 149ms/step - loss: 2.3294 - target_class_loss: 1.7046 - before_after_loss: 0.6248 - target_class_multi_acc: 0.5209 - before_after_single_acc: 0.6508 - val_loss: 4.0808 - val_target_class_loss: 2.6076 - val_before_after_loss: 1.4732 - val_target_class_multi_acc: 0.5133 - val_before_after_single_acc: 0.5110\n",
            "Epoch 11/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.3168 - target_class_loss: 1.6948 - before_after_loss: 0.6221 - target_class_multi_acc: 0.5183 - before_after_single_acc: 0.6554\n",
            "Epoch 11: val_loss did not improve from 2.58747\n",
            "100/100 [==============================] - 15s 149ms/step - loss: 2.3168 - target_class_loss: 1.6948 - before_after_loss: 0.6221 - target_class_multi_acc: 0.5183 - before_after_single_acc: 0.6554 - val_loss: 4.1551 - val_target_class_loss: 2.6457 - val_before_after_loss: 1.5094 - val_target_class_multi_acc: 0.4995 - val_before_after_single_acc: 0.5161\n",
            "Epoch 12/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.3344 - target_class_loss: 1.7116 - before_after_loss: 0.6229 - target_class_multi_acc: 0.5214 - before_after_single_acc: 0.6534\n",
            "Epoch 12: val_loss did not improve from 2.58747\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 2.3344 - target_class_loss: 1.7116 - before_after_loss: 0.6229 - target_class_multi_acc: 0.5214 - before_after_single_acc: 0.6534 - val_loss: 2.7978 - val_target_class_loss: 1.8921 - val_before_after_loss: 0.9057 - val_target_class_multi_acc: 0.5097 - val_before_after_single_acc: 0.5391\n",
            "Epoch 13/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.3144 - target_class_loss: 1.7027 - before_after_loss: 0.6117 - target_class_multi_acc: 0.5214 - before_after_single_acc: 0.6671\n",
            "Epoch 13: val_loss did not improve from 2.58747\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 2.3144 - target_class_loss: 1.7027 - before_after_loss: 0.6117 - target_class_multi_acc: 0.5214 - before_after_single_acc: 0.6671 - val_loss: 2.6795 - val_target_class_loss: 1.8418 - val_before_after_loss: 0.8377 - val_target_class_multi_acc: 0.5046 - val_before_after_single_acc: 0.5230\n",
            "Epoch 14/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.3244 - target_class_loss: 1.7194 - before_after_loss: 0.6050 - target_class_multi_acc: 0.5170 - before_after_single_acc: 0.6709\n",
            "Epoch 14: val_loss did not improve from 2.58747\n",
            "100/100 [==============================] - 15s 149ms/step - loss: 2.3244 - target_class_loss: 1.7194 - before_after_loss: 0.6050 - target_class_multi_acc: 0.5170 - before_after_single_acc: 0.6709 - val_loss: 2.6814 - val_target_class_loss: 1.8556 - val_before_after_loss: 0.8257 - val_target_class_multi_acc: 0.4876 - val_before_after_single_acc: 0.5202\n",
            "Epoch 15/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.2719 - target_class_loss: 1.6733 - before_after_loss: 0.5985 - target_class_multi_acc: 0.5323 - before_after_single_acc: 0.6839\n",
            "Epoch 15: val_loss did not improve from 2.58747\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 2.2719 - target_class_loss: 1.6733 - before_after_loss: 0.5985 - target_class_multi_acc: 0.5323 - before_after_single_acc: 0.6839 - val_loss: 5.0888 - val_target_class_loss: 3.1261 - val_before_after_loss: 1.9627 - val_target_class_multi_acc: 0.5119 - val_before_after_single_acc: 0.5129\n",
            "Epoch 16/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.2337 - target_class_loss: 1.6390 - before_after_loss: 0.5947 - target_class_multi_acc: 0.5248 - before_after_single_acc: 0.6858\n",
            "Epoch 16: val_loss did not improve from 2.58747\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 2.2337 - target_class_loss: 1.6390 - before_after_loss: 0.5947 - target_class_multi_acc: 0.5248 - before_after_single_acc: 0.6858 - val_loss: 2.7599 - val_target_class_loss: 1.9383 - val_before_after_loss: 0.8216 - val_target_class_multi_acc: 0.4407 - val_before_after_single_acc: 0.5786\n",
            "Epoch 17/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.2793 - target_class_loss: 1.6800 - before_after_loss: 0.5993 - target_class_multi_acc: 0.5243 - before_after_single_acc: 0.6809\n",
            "Epoch 17: val_loss improved from 2.58747 to 2.55697, saving model to best.h5\n",
            "100/100 [==============================] - 15s 153ms/step - loss: 2.2793 - target_class_loss: 1.6800 - before_after_loss: 0.5993 - target_class_multi_acc: 0.5243 - before_after_single_acc: 0.6809 - val_loss: 2.5570 - val_target_class_loss: 1.8216 - val_before_after_loss: 0.7354 - val_target_class_multi_acc: 0.4784 - val_before_after_single_acc: 0.5832\n",
            "Epoch 18/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.2614 - target_class_loss: 1.6711 - before_after_loss: 0.5903 - target_class_multi_acc: 0.5323 - before_after_single_acc: 0.6886\n",
            "Epoch 18: val_loss did not improve from 2.55697\n",
            "100/100 [==============================] - 16s 155ms/step - loss: 2.2614 - target_class_loss: 1.6711 - before_after_loss: 0.5903 - target_class_multi_acc: 0.5323 - before_after_single_acc: 0.6886 - val_loss: 2.5955 - val_target_class_loss: 1.8299 - val_before_after_loss: 0.7656 - val_target_class_multi_acc: 0.4265 - val_before_after_single_acc: 0.5216\n",
            "Epoch 19/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.2859 - target_class_loss: 1.6904 - before_after_loss: 0.5954 - target_class_multi_acc: 0.5213 - before_after_single_acc: 0.6823\n",
            "Epoch 19: val_loss did not improve from 2.55697\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 2.2859 - target_class_loss: 1.6904 - before_after_loss: 0.5954 - target_class_multi_acc: 0.5213 - before_after_single_acc: 0.6823 - val_loss: 2.9894 - val_target_class_loss: 1.9996 - val_before_after_loss: 0.9899 - val_target_class_multi_acc: 0.4674 - val_before_after_single_acc: 0.5092\n",
            "Epoch 20/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.2256 - target_class_loss: 1.6409 - before_after_loss: 0.5847 - target_class_multi_acc: 0.5356 - before_after_single_acc: 0.6916\n",
            "Epoch 20: val_loss did not improve from 2.55697\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 2.2256 - target_class_loss: 1.6409 - before_after_loss: 0.5847 - target_class_multi_acc: 0.5356 - before_after_single_acc: 0.6916 - val_loss: 4.4350 - val_target_class_loss: 2.8772 - val_before_after_loss: 1.5578 - val_target_class_multi_acc: 0.5097 - val_before_after_single_acc: 0.5248\n",
            "Epoch 21/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.2014 - target_class_loss: 1.6224 - before_after_loss: 0.5790 - target_class_multi_acc: 0.5287 - before_after_single_acc: 0.6963\n",
            "Epoch 21: val_loss did not improve from 2.55697\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 2.2014 - target_class_loss: 1.6224 - before_after_loss: 0.5790 - target_class_multi_acc: 0.5287 - before_after_single_acc: 0.6963 - val_loss: 3.4019 - val_target_class_loss: 2.3357 - val_before_after_loss: 1.0662 - val_target_class_multi_acc: 0.4665 - val_before_after_single_acc: 0.5464\n",
            "Epoch 22/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.2354 - target_class_loss: 1.6522 - before_after_loss: 0.5832 - target_class_multi_acc: 0.5348 - before_after_single_acc: 0.6945\n",
            "Epoch 22: val_loss did not improve from 2.55697\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 2.2354 - target_class_loss: 1.6522 - before_after_loss: 0.5832 - target_class_multi_acc: 0.5348 - before_after_single_acc: 0.6945 - val_loss: 3.2070 - val_target_class_loss: 2.2093 - val_before_after_loss: 0.9977 - val_target_class_multi_acc: 0.3755 - val_before_after_single_acc: 0.5772\n",
            "Epoch 23/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.2242 - target_class_loss: 1.6473 - before_after_loss: 0.5768 - target_class_multi_acc: 0.5383 - before_after_single_acc: 0.6970\n",
            "Epoch 23: val_loss improved from 2.55697 to 2.34749, saving model to best.h5\n",
            "100/100 [==============================] - 15s 154ms/step - loss: 2.2242 - target_class_loss: 1.6473 - before_after_loss: 0.5768 - target_class_multi_acc: 0.5383 - before_after_single_acc: 0.6970 - val_loss: 2.3475 - val_target_class_loss: 1.6988 - val_before_after_loss: 0.6487 - val_target_class_multi_acc: 0.5175 - val_before_after_single_acc: 0.6268\n",
            "Epoch 24/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.2353 - target_class_loss: 1.6596 - before_after_loss: 0.5757 - target_class_multi_acc: 0.5288 - before_after_single_acc: 0.6981\n",
            "Epoch 24: val_loss did not improve from 2.34749\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 2.2353 - target_class_loss: 1.6596 - before_after_loss: 0.5757 - target_class_multi_acc: 0.5288 - before_after_single_acc: 0.6981 - val_loss: 2.7915 - val_target_class_loss: 1.9716 - val_before_after_loss: 0.8199 - val_target_class_multi_acc: 0.4903 - val_before_after_single_acc: 0.5979\n",
            "Epoch 25/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.1893 - target_class_loss: 1.6158 - before_after_loss: 0.5735 - target_class_multi_acc: 0.5400 - before_after_single_acc: 0.7062\n",
            "Epoch 25: val_loss did not improve from 2.34749\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 2.1893 - target_class_loss: 1.6158 - before_after_loss: 0.5735 - target_class_multi_acc: 0.5400 - before_after_single_acc: 0.7062 - val_loss: 2.8557 - val_target_class_loss: 1.9738 - val_before_after_loss: 0.8819 - val_target_class_multi_acc: 0.5097 - val_before_after_single_acc: 0.5869\n",
            "Epoch 26/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.1635 - target_class_loss: 1.5931 - before_after_loss: 0.5705 - target_class_multi_acc: 0.5344 - before_after_single_acc: 0.7072\n",
            "Epoch 26: val_loss did not improve from 2.34749\n",
            "100/100 [==============================] - 15s 149ms/step - loss: 2.1635 - target_class_loss: 1.5931 - before_after_loss: 0.5705 - target_class_multi_acc: 0.5344 - before_after_single_acc: 0.7072 - val_loss: 4.5273 - val_target_class_loss: 2.8344 - val_before_after_loss: 1.6929 - val_target_class_multi_acc: 0.5014 - val_before_after_single_acc: 0.5340\n",
            "Epoch 27/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.2099 - target_class_loss: 1.6358 - before_after_loss: 0.5741 - target_class_multi_acc: 0.5359 - before_after_single_acc: 0.7002\n",
            "Epoch 27: val_loss did not improve from 2.34749\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 2.2099 - target_class_loss: 1.6358 - before_after_loss: 0.5741 - target_class_multi_acc: 0.5359 - before_after_single_acc: 0.7002 - val_loss: 2.7617 - val_target_class_loss: 1.9163 - val_before_after_loss: 0.8454 - val_target_class_multi_acc: 0.5097 - val_before_after_single_acc: 0.5473\n",
            "Epoch 28/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.1787 - target_class_loss: 1.6147 - before_after_loss: 0.5640 - target_class_multi_acc: 0.5491 - before_after_single_acc: 0.7122\n",
            "Epoch 28: val_loss did not improve from 2.34749\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 2.1787 - target_class_loss: 1.6147 - before_after_loss: 0.5640 - target_class_multi_acc: 0.5491 - before_after_single_acc: 0.7122 - val_loss: 2.6417 - val_target_class_loss: 1.8471 - val_before_after_loss: 0.7946 - val_target_class_multi_acc: 0.4931 - val_before_after_single_acc: 0.5607\n",
            "Epoch 29/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.2101 - target_class_loss: 1.6409 - before_after_loss: 0.5692 - target_class_multi_acc: 0.5309 - before_after_single_acc: 0.7098\n",
            "Epoch 29: val_loss did not improve from 2.34749\n",
            "100/100 [==============================] - 18s 181ms/step - loss: 2.2101 - target_class_loss: 1.6409 - before_after_loss: 0.5692 - target_class_multi_acc: 0.5309 - before_after_single_acc: 0.7098 - val_loss: 3.0711 - val_target_class_loss: 2.1506 - val_before_after_loss: 0.9205 - val_target_class_multi_acc: 0.4049 - val_before_after_single_acc: 0.5593\n",
            "Epoch 30/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.1614 - target_class_loss: 1.6008 - before_after_loss: 0.5607 - target_class_multi_acc: 0.5459 - before_after_single_acc: 0.7159\n",
            "Epoch 30: val_loss did not improve from 2.34749\n",
            "100/100 [==============================] - 17s 173ms/step - loss: 2.1614 - target_class_loss: 1.6008 - before_after_loss: 0.5607 - target_class_multi_acc: 0.5459 - before_after_single_acc: 0.7159 - val_loss: 3.9162 - val_target_class_loss: 2.5677 - val_before_after_loss: 1.3485 - val_target_class_multi_acc: 0.5138 - val_before_after_single_acc: 0.5524\n",
            "Epoch 31/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.1196 - target_class_loss: 1.5654 - before_after_loss: 0.5542 - target_class_multi_acc: 0.5476 - before_after_single_acc: 0.7213"
          ]
        }
      ],
      "source": [
        "model_name = 'ITIME_BOTH'\n",
        "# model_name = 'CONVMHSA_BOTH'\n",
        "save_path = ''\n",
        "\n",
        "        \n",
        "flight_res = []\n",
        "\n",
        "\n",
        "for fold in tqdm(range(5)): \n",
        "\n",
        "    save_filename = save_path + '%s_%i' % (model_name, fold)\n",
        "    \n",
        "\n",
        "    train_ds = dm.get_tf_dataset(fold = fold, training = True, shuffle = 1000, repeat = True, mode = mode, batch_size = 128)\n",
        "    test_ds = dm.get_tf_dataset(fold = fold, training  = False, shuffle = False, repeat = False, mode = mode, batch_size = 128)\n",
        "\n",
        "\n",
        "    with strategy.scope():\n",
        "        model = Classifier_INCEPTION(input_shape = (4096, 23), nb_classes=nb_classes, two_output = two_output ).model\n",
        "        lr = 1e-4\n",
        "\n",
        "        # model = get_mhsa_model(nbclass=nb_classes, mode = mode)\n",
        "        # lr = 3e-5\n",
        "\n",
        "        if two_output: \n",
        "                        \n",
        "            model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=lr),\n",
        "                        metrics = \n",
        "                                    {'target_class' : [tf.keras.metrics.SparseCategoricalAccuracy(name = 'multi_acc')],\n",
        "                                    'before_after' : [tf.keras.metrics.BinaryAccuracy(name = 'single_acc')],\n",
        "                                    }\n",
        "\n",
        "                        , \n",
        "                        loss = {'target_class' : tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False, name = 'multi_loss'),\n",
        "                                'before_after' : tf.keras.losses.BinaryCrossentropy(from_logits=False, name = 'single_loss')}\n",
        "            )\n",
        "\n",
        "\n",
        "        elif mode == 'before_after':\n",
        "                \n",
        "            model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=lr),\n",
        "                        metrics = [\n",
        "                                    tf.keras.metrics.BinaryAccuracy()\n",
        "                        ], \n",
        "                        loss = tf.keras.losses.BinaryCrossentropy(from_logits=False))\n",
        "\n",
        "\n",
        "        elif mode == 'classes':\n",
        "                \n",
        "            model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=lr),\n",
        "                        metrics = [\n",
        "                                    tf.keras.metrics.SparseCategoricalAccuracy(name = 'multi_acc')\n",
        "                        ], \n",
        "                        loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False))\n",
        "            \n",
        "        else:\n",
        "            raise \n",
        "       \n",
        "\n",
        "        callbacks = [\n",
        "                tf.keras.callbacks.ModelCheckpoint(\n",
        "                    filepath=\"best.h5\",\n",
        "                    save_best_only=True,  # Only save a model if `val_loss` has improved.\n",
        "                    monitor=\"val_loss\",\n",
        "                    verbose=1,\n",
        "                    save_weights_only=True\n",
        "                )\n",
        "            ]\n",
        "\n",
        "\n",
        "        history = model.fit(\n",
        "            train_ds,\n",
        "            steps_per_epoch = 100, \n",
        "            epochs = 200, \n",
        "            validation_data = test_ds,\n",
        "            callbacks = callbacks,\n",
        "            verbose = True, \n",
        "\n",
        "        )\n",
        "\n",
        "        history = pd.DataFrame(history.history)\n",
        "        history['epoch'] = history.index\n",
        "        history['model'] = model_name\n",
        "        history.to_csv(save_filename)\n",
        "\n",
        "        model.load_weights('best.h5')\n",
        "\n",
        "\n",
        "        flights_before_acc = {}\n",
        "\n",
        "        for day in ['0', '1', '2', '3', '4']:\n",
        "                \n",
        "\n",
        "            indices = list(dm.flight_header_df[ (dm.flight_header_df['number_flights_before'] == day) & (dm.flight_header_df.before_after == 1) & (dm.flight_header_df.fold == fold) & (dm.flight_header_df.label == 'intake gasket leak/damage')].index)\n",
        "            print(len(indices))\n",
        "            ds = tf.data.Dataset.from_tensor_slices(to_dict_of_list([example for example in dm.data_dict if example['id'] in indices]))\n",
        "\n",
        "            ds = dm.get_tf_dataset(ds = ds , fold = 0, training  = False, shuffle = False, repeat = False, mode = mode, batch_size = 2)\n",
        "            \n",
        "            res = model.evaluate(ds)\n",
        "\n",
        "            flights_before_acc[day] = res[-1]\n",
        "            \n",
        "        flight_res.append(flights_before_acc)\n",
        "        \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qfotnkc8cMd8"
      },
      "outputs": [],
      "source": [
        "flight_res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nDMVQso0W-WI"
      },
      "outputs": [],
      "source": [
        "\n",
        "history\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yVi6VtPpOxmQ"
      },
      "outputs": [],
      "source": [
        "dm.flight_header_df.groupby('target_class').count()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TT8jMM9nMAtw"
      },
      "outputs": [],
      "source": [
        "preds = model.predict(test_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wzbagtVoMJ67"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "\n",
        "np.argmax(preds[0], axis = 1)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UyH715ENMhSO"
      },
      "outputs": [],
      "source": [
        "\n",
        "target = [] \n",
        "\n",
        "\n",
        "for example in test_ds:\n",
        "    target.append(example[1]['target_class'])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xuR563YqM_Qv"
      },
      "outputs": [],
      "source": [
        "\n",
        "targets = tf.concat(target, axis = 0)\n",
        "\n",
        "class_preds = np.argmax(preds[0], axis = 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22cIOU6rNWZj"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame( {'test' : class_preds})\n",
        "\n",
        "df['abc'] = df.test\n",
        "\n",
        "df.groupby('test').count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4av6HBFsQ1pQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "pd.DataFrame(confusion_matrix(targets, class_preds))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vvsEfGPCMX_Q"
      },
      "outputs": [],
      "source": [
        "\n",
        "dm.flight_header_df[dm.flight_header_df.fold == 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1TEFVdKvnZG_"
      },
      "outputs": [],
      "source": [
        "\n",
        "flight_res = []\n",
        "\n",
        "\n",
        "flights_before_acc = {}\n",
        "\n",
        "for day in ['0', '1', '2', '3', '4']:\n",
        "        \n",
        "\n",
        "    indices = list(dm.flight_header_df[ (dm.flight_header_df['number_flights_before'] == day) & (dm.flight_header_df.before_after == 1) & (dm.flight_header_df.fold == 0) & (dm.flight_header_df.label == 'intake gasket leak/damage')].index)\n",
        "    print(len(indices))\n",
        "    ds = tf.data.Dataset.from_tensor_slices(to_dict_of_list([example for example in dm.data_dict if example['id'] in indices]))\n",
        "\n",
        "    ds = dm.get_tf_dataset(ds = ds , fold = 0, training  = False, shuffle = False, repeat = False, mode = mode, batch_size = 2)\n",
        "    \n",
        "    res = model.evaluate(ds)\n",
        "\n",
        "    flights_before_acc[day] = res[-1]\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J1GRUqARYwAJ"
      },
      "outputs": [],
      "source": [
        "res = model.evaluate(ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nn7eaaPYYwmU"
      },
      "outputs": [],
      "source": [
        "res[-1]"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [
        "9NBLjv7UgsWd"
      ],
      "name": "NGAFID DATASET TF EXAMPLE.ipynb",
      "provenance": [],
      "mount_file_id": "1SidmvHoUH0H4Ez8BzG-2Wyrjwbs8lxit",
      "authorship_tag": "ABX9TyNeshNHsSFTm8EwcPPXs8Ov",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "17cd17ddd64247be8604b1a634d864d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4daf288c958e4a14a8875d10fb0990f8",
              "IPY_MODEL_733144cac2704989a3900131fa31a612",
              "IPY_MODEL_ea445d2e6ac24209874559c87f04f87b"
            ],
            "layout": "IPY_MODEL_3cf5bf042a304ef38c3d95af0dae98d6"
          }
        },
        "4daf288c958e4a14a8875d10fb0990f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc5f065deac34a3089870ef8ce6c5520",
            "placeholder": "​",
            "style": "IPY_MODEL_730d73e86352458d985ca4e11e2e52d5",
            "value": "100%"
          }
        },
        "733144cac2704989a3900131fa31a612": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64f8f635e54748dfada9321fc315e89c",
            "max": 11446,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_67ebbe7d85db455f8a87a1109e2dd6d3",
            "value": 11446
          }
        },
        "ea445d2e6ac24209874559c87f04f87b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_696a4a4233074dd09fe98e7a17bb0d1e",
            "placeholder": "​",
            "style": "IPY_MODEL_7774690c444047c6a76733aa02f14621",
            "value": " 11446/11446 [00:32&lt;00:00, 369.27it/s]"
          }
        },
        "3cf5bf042a304ef38c3d95af0dae98d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc5f065deac34a3089870ef8ce6c5520": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "730d73e86352458d985ca4e11e2e52d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "64f8f635e54748dfada9321fc315e89c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67ebbe7d85db455f8a87a1109e2dd6d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "696a4a4233074dd09fe98e7a17bb0d1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7774690c444047c6a76733aa02f14621": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "61448d8920c34a4da4eef6762526d81a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e670557cec5d4ce484cdc5b769406320",
              "IPY_MODEL_2c4626cb3c1249d4869cca9f3d7a71e0",
              "IPY_MODEL_37a136e3b89e42e7b3dd793afaf2b07f"
            ],
            "layout": "IPY_MODEL_74f9aba46a3e4b40959d863d8a68aab6"
          }
        },
        "e670557cec5d4ce484cdc5b769406320": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77d1972762c04187b67975e9774591ea",
            "placeholder": "​",
            "style": "IPY_MODEL_a98e9cedb63e4278952e471862734ae4",
            "value": "  0%"
          }
        },
        "2c4626cb3c1249d4869cca9f3d7a71e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64cebde0e00643b2aa1a971d8fd5a856",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9dca06eb92eb42afac8da02646aeed9f",
            "value": 0
          }
        },
        "37a136e3b89e42e7b3dd793afaf2b07f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_748fdf920c634b58b2f92434db9ed5db",
            "placeholder": "​",
            "style": "IPY_MODEL_6f7eee80fea64072b3cf00fc9e76079e",
            "value": " 0/5 [00:00&lt;?, ?it/s]"
          }
        },
        "74f9aba46a3e4b40959d863d8a68aab6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77d1972762c04187b67975e9774591ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a98e9cedb63e4278952e471862734ae4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "64cebde0e00643b2aa1a971d8fd5a856": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9dca06eb92eb42afac8da02646aeed9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "748fdf920c634b58b2f92434db9ed5db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f7eee80fea64072b3cf00fc9e76079e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}