{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyang0129/NGAFIDDATASET/blob/main/NGAFID_DATASET_TF_EXAMPLE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NBLjv7UgsWd"
      },
      "source": [
        "# INSTALL PREREQ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0X2aMD0lLrg",
        "outputId": "a0e15135-4445-475d-ced1-9034af2fc9a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'NGAFIDDATASET' already exists and is not an empty directory.\n",
            "Already on 'main'\n",
            "Your branch is up to date with 'origin/main'.\n",
            "HEAD is now at 63bfe48 Update README.md\n",
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 3 (delta 2), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (3/3), done.\n",
            "From https://github.com/hyang0129/NGAFIDDATASET\n",
            "   63bfe48..62cc5dc  main       -> origin/main\n",
            "Updating 63bfe48..62cc5dc\n",
            "Fast-forward\n",
            " NGAFID_DATASET_DASK_EXAMPLE.ipynb | 544 \u001b[32m++++++++++++++++\u001b[m\u001b[31m----------------------\u001b[m\n",
            " 1 file changed, 235 insertions(+), 309 deletions(-)\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/hyang0129/NGAFIDDATASET.git\n",
        "\n",
        "!(cd NGAFIDDATASET ; git checkout main; git reset --hard HEAD; git pull)\n",
        "!(cd NGAFIDDATASET ; pip install -r requirements.txt -q)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jb948fwpgvDN"
      },
      "source": [
        "# IMPORT DEPENDENCIES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "BscNhNpszOl3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0864cad-064a-449f-862b-5251d55acc06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "027FHavVxd-g"
      },
      "outputs": [],
      "source": [
        "import sys \n",
        "sys.path.append('/content/NGAFIDDATASET')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "8s4eIqhm1AiX"
      },
      "outputs": [],
      "source": [
        "from tqdm.autonotebook import tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgLDpCrBxkiP",
        "outputId": "0ad5c1a5-1e81-4bbf-d632-6af260ed3c5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TPU address is grpc://10.60.13.250:8470\n",
            "Running on TPU  grpc://10.60.13.250:8470\n",
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.60.13.250:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.60.13.250:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.60.13.250:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.60.13.250:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "REPLICAS:  8\n"
          ]
        }
      ],
      "source": [
        "%autoreload\n",
        "from ngafiddataset.dataset.dataset import NGAFID_Dataset_Manager\n",
        "from ngafiddataset.dataset.utils import to_dict_of_list\n",
        "from ngafiddataset.utils import connect_to_tpu\n",
        "import pandas as pd \n",
        "\n",
        "\n",
        "strategy = connect_to_tpu()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfrR0ZDrg2N8"
      },
      "source": [
        "# DEFINE MODEL FN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "D6IBWF6lg3gn"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "tfk = tf.keras\n",
        "tfkl = tf.keras.layers\n",
        "\n",
        "class Classifier_INCEPTION:\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_shape,\n",
        "        nb_classes,\n",
        "        build=True,\n",
        "        batch_size=64,\n",
        "        nb_filters=32,\n",
        "        use_residual=True,\n",
        "        use_bottleneck=True,\n",
        "        depth=6,\n",
        "        kernel_size=41,\n",
        "        nb_epochs=1500,\n",
        "        two_output = False, \n",
        "        mode = None\n",
        "    ):\n",
        "\n",
        "        self.nb_filters = nb_filters\n",
        "        self.use_residual = use_residual\n",
        "        self.use_bottleneck = use_bottleneck\n",
        "        self.depth = depth\n",
        "        self.kernel_size = kernel_size - 1\n",
        "        self.callbacks = None\n",
        "        self.batch_size = batch_size\n",
        "        self.bottleneck_size = 32\n",
        "        self.nb_epochs = nb_epochs\n",
        "        self.two_output = two_output \n",
        "        self.mode = mode \n",
        "\n",
        "        if build is True:\n",
        "            self.model = self.build_model(input_shape, nb_classes)\n",
        "\n",
        "    def _inception_module(self, input_tensor, stride=1, activation=\"linear\"):\n",
        "\n",
        "        if self.use_bottleneck and int(input_tensor.shape[-1]) > 1:\n",
        "            input_inception = tf.keras.layers.Conv1D(\n",
        "                filters=self.bottleneck_size, kernel_size=1, padding=\"same\", activation=activation, use_bias=False\n",
        "            )(input_tensor)\n",
        "        else:\n",
        "            input_inception = input_tensor\n",
        "\n",
        "        # kernel_size_s = [3, 5, 8, 11, 17]\n",
        "        kernel_size_s = [self.kernel_size // (2 ** i) for i in range(3)]\n",
        "\n",
        "        conv_list = []\n",
        "\n",
        "        for i in range(len(kernel_size_s)):\n",
        "            conv_list.append(\n",
        "                tf.keras.layers.Conv1D(\n",
        "                    filters=self.nb_filters,\n",
        "                    kernel_size=kernel_size_s[i],\n",
        "                    strides=stride,\n",
        "                    padding=\"same\",\n",
        "                    activation=activation,\n",
        "                    use_bias=False,\n",
        "                )(input_inception)\n",
        "            )\n",
        "\n",
        "        max_pool_1 = tf.keras.layers.MaxPool1D(pool_size=3, strides=stride, padding=\"same\")(input_tensor)\n",
        "\n",
        "        conv_6 = tf.keras.layers.Conv1D(\n",
        "            filters=self.nb_filters, kernel_size=1, padding=\"same\", activation=activation, use_bias=False\n",
        "        )(max_pool_1)\n",
        "\n",
        "        conv_list.append(conv_6)\n",
        "\n",
        "        x = tf.keras.layers.Concatenate(axis=2)(conv_list)\n",
        "        x = tf.keras.layers.BatchNormalization()(x)\n",
        "        x = tf.keras.layers.Activation(activation=\"relu\")(x)\n",
        "        return x\n",
        "\n",
        "    def _shortcut_layer(self, input_tensor, out_tensor):\n",
        "        shortcut_y = tf.keras.layers.Conv1D(\n",
        "            filters=int(out_tensor.shape[-1]), kernel_size=1, padding=\"same\", use_bias=False\n",
        "        )(input_tensor)\n",
        "        shortcut_y = tf.keras.layers.BatchNormalization()(shortcut_y)\n",
        "\n",
        "        x = tf.keras.layers.Add()([shortcut_y, out_tensor])\n",
        "        x = tf.keras.layers.Activation(\"relu\")(x)\n",
        "        return x\n",
        "\n",
        "    def build_model(self, input_shape, nb_classes):\n",
        "        input_layer = tf.keras.layers.Input(input_shape, name = 'data')\n",
        "\n",
        "        x = input_layer\n",
        "        input_res = input_layer\n",
        "\n",
        "        for d in range(self.depth):\n",
        "\n",
        "            x = self._inception_module(x)\n",
        "\n",
        "            if self.use_residual and d % 3 == 2:\n",
        "                x = self._shortcut_layer(input_res, x)\n",
        "                input_res = x\n",
        "\n",
        "        gap_layer = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
        "\n",
        "        \n",
        "        outputs = [] \n",
        "\n",
        "        outputs.append(tf.keras.layers.Dense(nb_classes, activation=\"softmax\", name='target_class')(gap_layer))\n",
        "\n",
        "        if self.two_output: \n",
        "            outputs.append(tf.keras.layers.Dense(1, activation=\"sigmoid\", name='before_after')(gap_layer))\n",
        "        \n",
        "        \n",
        "        if self.mode == 'before_after':\n",
        "            outputs = [] \n",
        "            outputs.append(tf.keras.layers.Dense(1, activation=\"sigmoid\", name='before_after')(gap_layer))\n",
        "\n",
        "        model = tf.keras.models.Model(inputs=input_layer, outputs=outputs)\n",
        "\n",
        "        return model\n",
        "\n",
        "    def get_kernel_model(self):\n",
        "        '''\n",
        "        Get a model whose output is just the global average pooling layer.\n",
        "\n",
        "        Returns:\n",
        "\n",
        "        '''\n",
        "\n",
        "        return tf.keras.Model(self.model.layers[0].input, self.model.layers[-2].output)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBAETchjmf-W",
        "outputId": "16fcd01f-093d-4123-b2be-d8b0c38e1cb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " data (InputLayer)              [(None, 4096, 23)]   0           []                               \n",
            "                                                                                                  \n",
            " sequential_14 (Sequential)     (None, 512)          10153344    ['data[0][0]']                   \n",
            "                                                                                                  \n",
            " target_class (Dense)           (None, 2)            1026        ['sequential_14[0][0]']          \n",
            "                                                                                                  \n",
            " before_after (Dense)           (None, 1)            513         ['sequential_14[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 10,154,883\n",
            "Trainable params: 10,154,883\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "def point_wise_feed_forward_network(d_model, dff):\n",
        "  return tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
        "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
        "  ])\n",
        "\n",
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "  \"\"\"Calculate the attention weights.\n",
        "  q, k, v must have matching leading dimensions.\n",
        "  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
        "  The mask has different shapes depending on its type(padding or look ahead)\n",
        "  but it must be broadcastable for addition.\n",
        "\n",
        "  Args:\n",
        "    q: query shape == (..., seq_len_q, depth)\n",
        "    k: key shape == (..., seq_len_k, depth)\n",
        "    v: value shape == (..., seq_len_v, depth_v)\n",
        "    mask: Float tensor with shape broadcastable\n",
        "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
        "\n",
        "  Returns:\n",
        "    output, attention_weights\n",
        "  \"\"\"\n",
        "\n",
        "  matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "  # scale matmul_qk\n",
        "  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "\n",
        "  # add the mask to the scaled tensor.\n",
        "  if mask is not None:\n",
        "    scaled_attention_logits += (mask * -1e9)\n",
        "\n",
        "  # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
        "  # add up to 1.\n",
        "  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "  output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
        "\n",
        "  return output, attention_weights\n",
        "\n",
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads):\n",
        "    super(MultiHeadAttention, self).__init__()\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "\n",
        "    assert d_model % self.num_heads == 0\n",
        "\n",
        "    self.depth = d_model // self.num_heads\n",
        "\n",
        "    self.wq = tf.keras.layers.Dense(d_model)\n",
        "    self.wk = tf.keras.layers.Dense(d_model)\n",
        "    self.wv = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "  def split_heads(self, x, batch_size):\n",
        "    \"\"\"Split the last dimension into (num_heads, depth).\n",
        "    Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
        "    \"\"\"\n",
        "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "  def call(self, v, k, q, mask):\n",
        "    batch_size = tf.shape(q)[0]\n",
        "\n",
        "    q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
        "    k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
        "    v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
        "\n",
        "    q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
        "    k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
        "    v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
        "\n",
        "    # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
        "    # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
        "    scaled_attention, attention_weights = scaled_dot_product_attention(\n",
        "        q, k, v, mask)\n",
        "\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
        "\n",
        "    concat_attention = tf.reshape(scaled_attention,\n",
        "                                  (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "    output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "    return output, attention_weights\n",
        "\n",
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "    super(EncoderLayer, self).__init__()\n",
        "\n",
        "    self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "  def call(self, x, training, mask = None):\n",
        "\n",
        "    attn_output, self.attention_values = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
        "    attn_output = self.dropout1(attn_output, training=training)\n",
        "    out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "    ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
        "    ffn_output = self.dropout2(ffn_output, training=training)\n",
        "    out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "    return out2\n",
        "\n",
        "def get_angles(pos, i, d_model):\n",
        "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
        "    return pos * angle_rates\n",
        "\n",
        "def positional_encoding(position, d_model):\n",
        "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
        "                            np.arange(d_model)[np.newaxis, :],\n",
        "                            d_model)\n",
        "\n",
        "    # apply sin to even indices in the array; 2i\n",
        "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "\n",
        "    # apply cos to odd indices in the array; 2i+1\n",
        "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    pos_encoding = angle_rads[np.newaxis, ...]\n",
        "\n",
        "    return tf.cast(pos_encoding, dtype=tf.float32)\n",
        "\n",
        "class PositionalEncoding(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, maximum_position_encoding = 1000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "\n",
        "        self.pos_encoding = positional_encoding(maximum_position_encoding,\n",
        "                                        512)\n",
        "\n",
        "    def call(self, x):\n",
        "\n",
        "        seq_len = tf.shape(x)[1]\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "        return x \n",
        "\n",
        "def get_mhsa_model(nbclass = 2, SHAPE = (4096, 23), mode = 'before_after'):\n",
        "    # I realize that I did not include a positional embedding, but its too late now. Maybe a future paper could address this? \n",
        "    d = 512\n",
        "    ff = 1024\n",
        "    model =  tfk.Sequential([tf.keras.Input(shape = SHAPE),\n",
        "                                            tfkl.Conv1D(128, 7, strides = 1, padding='same', activation='relu'),\n",
        "                                            # tfkl.BatchNormalization(),\n",
        "                                            tfkl.Conv1D(128, 7, strides = 2, padding='same', activation='relu'),\n",
        "                                            # tfkl.BatchNormalization(),\n",
        "                                            tfkl.Conv1D(256, 7, strides = 1, padding='same', activation='relu'),\n",
        "                                            # tfkl.BatchNormalization(),\n",
        "                                            tfkl.Conv1D(256, 7, strides = 2, padding='same', activation='relu'),\n",
        "                                            # tfkl.BatchNormalization(),\n",
        "                                            # tfkl.Conv1D(512, 7, strides = 1, padding='same', activation='relu'),\n",
        "                                            tfkl.Conv1D(512, 7, strides = 2, padding='same', activation='relu'),\n",
        "                                            # tfkl.Conv1D(768, 7, strides = 1, padding='same', activation='relu'),\n",
        "                                            # tfkl.BatchNormalization(),\n",
        "                                            EncoderLayer(d_model=d, num_heads=8, dff=ff),\n",
        "                                            EncoderLayer(d_model=d, num_heads=8, dff=ff),\n",
        "                                            EncoderLayer(d_model=d, num_heads=8, dff=ff),\n",
        "                                            EncoderLayer(d_model=d, num_heads=8, dff=ff),\n",
        "                                            \n",
        "                                            tf.keras.layers.GlobalAveragePooling1D(),\n",
        "                                            # tfkl.Dense(nbclass, activation='softmax'),\n",
        "    ])\n",
        "\n",
        "\n",
        "    input = tf.keras.Input(shape = SHAPE, name = 'data')\n",
        "\n",
        "    x = model(input)\n",
        "\n",
        "    output = []\n",
        "    if mode == 'before_after': \n",
        "        output =  tfkl.Dense(1, activation='sigmoid', name = 'before_after')(x)\n",
        "    elif mode == 'both': \n",
        "        output.append(tf.keras.layers.Dense(nbclass, activation=\"softmax\", name='target_class')(x))\n",
        "        output.append(tfkl.Dense(1, activation='sigmoid', name = 'before_after')(x))\n",
        "    elif mode == 'classes': \n",
        "        output.append(tf.keras.layers.Dense(nbclass, activation=\"softmax\", name='target_class')(x))\n",
        "\n",
        "    fun_model = tf.keras.Model(input, output)\n",
        "\n",
        "    return fun_model\n",
        "\n",
        "def get_mhsa_model_pe():\n",
        "    # I realize that I did not include a positional embedding, but its too late now. Maybe a future paper could address this? \n",
        "\n",
        "    model =  tfk.Sequential([tf.keras.Input(shape = SHAPE),\n",
        "                                            tfkl.Conv1D(128, 7, strides = 1, padding='same', activation='relu'),\n",
        "                                            tfkl.BatchNormalization(),\n",
        "                                            tfkl.Conv1D(128, 7, strides = 2, padding='same', activation='relu'),\n",
        "                                            tfkl.BatchNormalization(),\n",
        "                                            tfkl.Conv1D(256, 3, strides = 1, padding='same', activation='relu'),\n",
        "                                            tfkl.BatchNormalization(),\n",
        "                                            tfkl.Conv1D(256, 7, strides = 2, padding='same', activation='relu'),\n",
        "                                            tfkl.BatchNormalization(),\n",
        "                                            tfkl.Conv1D(512, 7, strides = 2, padding='same', activation='relu'),\n",
        "                                            tfkl.BatchNormalization(),\n",
        "                                            # tfkl.Conv1D(512, 7, strides = 2, padding='same', activation='relu'),\n",
        "                                            # tfkl.Conv1D(512, 7, strides = 2, padding='same', activation='relu'),\n",
        "                                            PositionalEncoding(),\n",
        "                                            EncoderLayer(d_model=512, num_heads=8, dff=512),\n",
        "                                            EncoderLayer(d_model=512, num_heads=8, dff=512),\n",
        "                                            EncoderLayer(d_model=512, num_heads=8, dff=512),\n",
        "                                            EncoderLayer(d_model=512, num_heads=8, dff=512),\n",
        "                                            # tfkl.Lambda(lambda x : x[:, 0, :]),\n",
        "                                            tf.keras.layers.GlobalAveragePooling1D(),\n",
        "                                            tfkl.Dense(1, activation='sigmoid'),\n",
        "    ])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "model = get_mhsa_model(mode = 'both')\n",
        "model.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jk4zIneNgwzO"
      },
      "source": [
        "# SETUP DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "ae033449ece34336b16b1b8c70f29a0e",
            "41b6364e3504485c9a1d77d70a85d33d",
            "8f48831840a94ac0acf6aef995f623d5",
            "d47c18b3d8174f7b910ad24985e645a9",
            "56f2e7e88f204e8080bc854e906795f3",
            "7d87d336ce104c5e8508e808fe470614",
            "3a91db044fa24d7f89803b86bc51c054",
            "ec848bdd788c492eb95b7facf799df07",
            "73eed9dd178d4e389ea79e30a9385c2b",
            "685d2977b2134c75bb4d741a25d364d5",
            "4ad47b2f08bb437590f06c2b946946ef"
          ]
        },
        "id": "kDYNIjFdtMEb",
        "outputId": "33e20698-b361-4a1b-ac8c-6dfbf18db73f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-06-09 16:15:01.675 | INFO     | ngafiddataset.dataset.dataset:download:39 - Extracting File\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/11446 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ae033449ece34336b16b1b8c70f29a0e"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "dm = NGAFID_Dataset_Manager('2days')\n",
        "df = pd.read_csv('/content/2days/flight_header.csv')\n",
        "\n",
        "dm.data_dict =  dm.construct_data_dictionary(numpy=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMlBnOGQ43jv",
        "outputId": "1f65140a-84c6-4858-f044-7e0e55e4243c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "number_classes = len(dm.flight_header_df['class'].unique())\n",
        "number_classes\n",
        "\n",
        "number_hierarchies = len(dm.flight_header_df['hclass'].unique())\n",
        "number_hierarchies\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_7rt6AvP8XgA"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUnni6illOea"
      },
      "source": [
        "# DEFINE TASK "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "MW93Quq24d3f"
      },
      "outputs": [],
      "source": [
        "# mode = 'before_after'\n",
        "# mode = 'hierarchy_basic'\n",
        "mode = 'both'\n",
        "# mode = 'classes'\n",
        "\n",
        "# DETERMINE MODEL STRUCTURE BASED ON OUTPUTS \n",
        "two_output = False\n",
        "if mode == 'before_after': \n",
        "    nb_classes = 1\n",
        "elif mode == 'hierarchy_basic':\n",
        "    nb_classes = number_hierarchies + 1\n",
        "    two_output = True \n",
        "elif mode == 'both':\n",
        "    two_output = True\n",
        "    nb_classes = number_classes+1\n",
        "else:\n",
        "    nb_classes = number_classes+1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l34Mz7tMlQri"
      },
      "source": [
        "# TRAIN MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "HM5qBjAXbLp8"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Saver(tf.keras.callbacks.Callback): \n",
        "    \n",
        "    def __init__(self, model_name): \n",
        "        super().__init__()\n",
        "        self.model_name = model_name \n",
        "        # self.bucket = bucket \n",
        "        # self.fs = gcsfs.GCSFileSystem(project='tpu-44747', token = 'gckey.json')\n",
        "        self.start = 5\n",
        "        self.best = 0\n",
        "    \n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if epoch > self.start: \n",
        "            pass\n",
        "        \n",
        "        metric = 'val_loss'\n",
        "\n",
        "        try: \n",
        "            if logs.get(metric) >= 0.85 and logs.get(metric) > self.best: \n",
        "                print('saving good model')\n",
        "                lpath = self.model_name + '.h5'\n",
        "                self.model.save(lpath, include_optimizer=False)\n",
        "                self.best = logs.get(metric)\n",
        "        except Exception as E:\n",
        "            print('encountered some error in model saving process')\n",
        "            print(E)\n",
        "            pass \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b84580d7b4ef44fcaf590a92cb5f059e",
            "1bc47cf3c19042eab2d18616f2f3ab26",
            "47d14723b7f14229ba60e46177282af1",
            "03d4dda7dd3140658b4de230426f7bdc",
            "746381eea2f24aa6a8fc1eb0dcb79d77",
            "bbd1939f519f4179b47e775dd9373cd7",
            "d2274730403c4592833c5c3177a39e20",
            "559c8ebd1c414b4e8e680598725d2423",
            "ddc0c360a6c140e6b532cae8b9624de0",
            "d40b7ad6b9024fe78fd7e39fe4b38e4d",
            "df765d955633452eb649708b9d0eb54b"
          ]
        },
        "id": "RM8oXegXiZvk",
        "outputId": "02416fd1-d52b-49f9-bee5-845b216ff2aa"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b84580d7b4ef44fcaf590a92cb5f059e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.1346 - target_class_loss: 2.4277 - before_after_loss: 0.7069 - target_class_multi_acc: 0.3394 - before_after_single_acc: 0.5345\n",
            "Epoch 1: val_loss improved from inf to 3.17702, saving model to best.h5\n",
            "100/100 [==============================] - 47s 209ms/step - loss: 3.1346 - target_class_loss: 2.4277 - before_after_loss: 0.7069 - target_class_multi_acc: 0.3394 - before_after_single_acc: 0.5345 - val_loss: 3.1770 - val_target_class_loss: 2.4730 - val_before_after_loss: 0.7040 - val_target_class_multi_acc: 0.4655 - val_before_after_single_acc: 0.5110\n",
            "Epoch 2/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.5555 - target_class_loss: 1.8770 - before_after_loss: 0.6785 - target_class_multi_acc: 0.5037 - before_after_single_acc: 0.5716\n",
            "Epoch 2: val_loss improved from 3.17702 to 2.85272, saving model to best.h5\n",
            "100/100 [==============================] - 16s 158ms/step - loss: 2.5555 - target_class_loss: 1.8770 - before_after_loss: 0.6785 - target_class_multi_acc: 0.5037 - before_after_single_acc: 0.5716 - val_loss: 2.8527 - val_target_class_loss: 1.9818 - val_before_after_loss: 0.8709 - val_target_class_multi_acc: 0.5023 - val_before_after_single_acc: 0.5115\n",
            "Epoch 3/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.4899 - target_class_loss: 1.8224 - before_after_loss: 0.6674 - target_class_multi_acc: 0.5044 - before_after_single_acc: 0.5895\n",
            "Epoch 3: val_loss improved from 2.85272 to 2.59920, saving model to best.h5\n",
            "100/100 [==============================] - 16s 159ms/step - loss: 2.4899 - target_class_loss: 1.8224 - before_after_loss: 0.6674 - target_class_multi_acc: 0.5044 - before_after_single_acc: 0.5895 - val_loss: 2.5992 - val_target_class_loss: 1.8524 - val_before_after_loss: 0.7468 - val_target_class_multi_acc: 0.5083 - val_before_after_single_acc: 0.5133\n",
            "Epoch 4/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.4854 - target_class_loss: 1.8234 - before_after_loss: 0.6620 - target_class_multi_acc: 0.5087 - before_after_single_acc: 0.5999\n",
            "Epoch 4: val_loss improved from 2.59920 to 2.52825, saving model to best.h5\n",
            "100/100 [==============================] - 16s 158ms/step - loss: 2.4854 - target_class_loss: 1.8234 - before_after_loss: 0.6620 - target_class_multi_acc: 0.5087 - before_after_single_acc: 0.5999 - val_loss: 2.5283 - val_target_class_loss: 1.8363 - val_before_after_loss: 0.6919 - val_target_class_multi_acc: 0.5119 - val_before_after_single_acc: 0.5409\n",
            "Epoch 5/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.4189 - target_class_loss: 1.7655 - before_after_loss: 0.6534 - target_class_multi_acc: 0.5077 - before_after_single_acc: 0.6110\n",
            "Epoch 5: val_loss did not improve from 2.52825\n",
            "100/100 [==============================] - 15s 153ms/step - loss: 2.4189 - target_class_loss: 1.7655 - before_after_loss: 0.6534 - target_class_multi_acc: 0.5077 - before_after_single_acc: 0.6110 - val_loss: 3.5993 - val_target_class_loss: 2.3035 - val_before_after_loss: 1.2959 - val_target_class_multi_acc: 0.5083 - val_before_after_single_acc: 0.5142\n",
            "Epoch 6/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.3786 - target_class_loss: 1.7285 - before_after_loss: 0.6501 - target_class_multi_acc: 0.5146 - before_after_single_acc: 0.6134\n",
            "Epoch 6: val_loss did not improve from 2.52825\n",
            "100/100 [==============================] - 15s 154ms/step - loss: 2.3786 - target_class_loss: 1.7285 - before_after_loss: 0.6501 - target_class_multi_acc: 0.5146 - before_after_single_acc: 0.6134 - val_loss: 2.6187 - val_target_class_loss: 1.9197 - val_before_after_loss: 0.6990 - val_target_class_multi_acc: 0.3892 - val_before_after_single_acc: 0.5294\n",
            "Epoch 7/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.4073 - target_class_loss: 1.7578 - before_after_loss: 0.6495 - target_class_multi_acc: 0.5091 - before_after_single_acc: 0.6209\n",
            "Epoch 7: val_loss did not improve from 2.52825\n",
            "100/100 [==============================] - 15s 154ms/step - loss: 2.4073 - target_class_loss: 1.7578 - before_after_loss: 0.6495 - target_class_multi_acc: 0.5091 - before_after_single_acc: 0.6209 - val_loss: 2.5727 - val_target_class_loss: 1.8408 - val_before_after_loss: 0.7319 - val_target_class_multi_acc: 0.5106 - val_before_after_single_acc: 0.5193\n",
            "Epoch 8/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.3943 - target_class_loss: 1.7501 - before_after_loss: 0.6443 - target_class_multi_acc: 0.5127 - before_after_single_acc: 0.6220\n",
            "Epoch 8: val_loss did not improve from 2.52825\n",
            "100/100 [==============================] - 15s 154ms/step - loss: 2.3943 - target_class_loss: 1.7501 - before_after_loss: 0.6443 - target_class_multi_acc: 0.5127 - before_after_single_acc: 0.6220 - val_loss: 2.5465 - val_target_class_loss: 1.8028 - val_before_after_loss: 0.7437 - val_target_class_multi_acc: 0.5106 - val_before_after_single_acc: 0.5331\n",
            "Epoch 9/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.4070 - target_class_loss: 1.7678 - before_after_loss: 0.6392 - target_class_multi_acc: 0.5102 - before_after_single_acc: 0.6287\n",
            "Epoch 9: val_loss improved from 2.52825 to 2.49332, saving model to best.h5\n",
            "100/100 [==============================] - 16s 158ms/step - loss: 2.4070 - target_class_loss: 1.7678 - before_after_loss: 0.6392 - target_class_multi_acc: 0.5102 - before_after_single_acc: 0.6287 - val_loss: 2.4933 - val_target_class_loss: 1.7889 - val_before_after_loss: 0.7045 - val_target_class_multi_acc: 0.5005 - val_before_after_single_acc: 0.5285\n",
            "Epoch 10/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.3564 - target_class_loss: 1.7223 - before_after_loss: 0.6341 - target_class_multi_acc: 0.5114 - before_after_single_acc: 0.6421\n",
            "Epoch 10: val_loss did not improve from 2.49332\n",
            "100/100 [==============================] - 15s 155ms/step - loss: 2.3564 - target_class_loss: 1.7223 - before_after_loss: 0.6341 - target_class_multi_acc: 0.5114 - before_after_single_acc: 0.6421 - val_loss: 2.7350 - val_target_class_loss: 1.9375 - val_before_after_loss: 0.7974 - val_target_class_multi_acc: 0.5119 - val_before_after_single_acc: 0.5161\n",
            "Epoch 11/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.3186 - target_class_loss: 1.6906 - before_after_loss: 0.6280 - target_class_multi_acc: 0.5146 - before_after_single_acc: 0.6496\n",
            "Epoch 11: val_loss did not improve from 2.49332\n",
            "100/100 [==============================] - 15s 155ms/step - loss: 2.3186 - target_class_loss: 1.6906 - before_after_loss: 0.6280 - target_class_multi_acc: 0.5146 - before_after_single_acc: 0.6496 - val_loss: 2.9682 - val_target_class_loss: 2.0560 - val_before_after_loss: 0.9122 - val_target_class_multi_acc: 0.3456 - val_before_after_single_acc: 0.5041\n",
            "Epoch 12/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.3512 - target_class_loss: 1.7258 - before_after_loss: 0.6254 - target_class_multi_acc: 0.5155 - before_after_single_acc: 0.6495\n",
            "Epoch 12: val_loss did not improve from 2.49332\n",
            "100/100 [==============================] - 15s 153ms/step - loss: 2.3512 - target_class_loss: 1.7258 - before_after_loss: 0.6254 - target_class_multi_acc: 0.5155 - before_after_single_acc: 0.6495 - val_loss: 2.9952 - val_target_class_loss: 2.0716 - val_before_after_loss: 0.9236 - val_target_class_multi_acc: 0.5041 - val_before_after_single_acc: 0.5216\n",
            "Epoch 13/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.3229 - target_class_loss: 1.7090 - before_after_loss: 0.6138 - target_class_multi_acc: 0.5189 - before_after_single_acc: 0.6636\n",
            "Epoch 13: val_loss did not improve from 2.49332\n",
            "100/100 [==============================] - 15s 154ms/step - loss: 2.3229 - target_class_loss: 1.7090 - before_after_loss: 0.6138 - target_class_multi_acc: 0.5189 - before_after_single_acc: 0.6636 - val_loss: 4.2960 - val_target_class_loss: 2.7587 - val_before_after_loss: 1.5373 - val_target_class_multi_acc: 0.5119 - val_before_after_single_acc: 0.5179\n",
            "Epoch 14/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.3444 - target_class_loss: 1.7322 - before_after_loss: 0.6122 - target_class_multi_acc: 0.5122 - before_after_single_acc: 0.6650\n",
            "Epoch 14: val_loss did not improve from 2.49332\n",
            "100/100 [==============================] - 16s 158ms/step - loss: 2.3444 - target_class_loss: 1.7322 - before_after_loss: 0.6122 - target_class_multi_acc: 0.5122 - before_after_single_acc: 0.6650 - val_loss: 2.5919 - val_target_class_loss: 1.8544 - val_before_after_loss: 0.7376 - val_target_class_multi_acc: 0.5074 - val_before_after_single_acc: 0.5823\n",
            "Epoch 15/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.2763 - target_class_loss: 1.6738 - before_after_loss: 0.6024 - target_class_multi_acc: 0.5275 - before_after_single_acc: 0.6728\n",
            "Epoch 15: val_loss did not improve from 2.49332\n",
            "100/100 [==============================] - 15s 155ms/step - loss: 2.2763 - target_class_loss: 1.6738 - before_after_loss: 0.6024 - target_class_multi_acc: 0.5275 - before_after_single_acc: 0.6728 - val_loss: 2.5870 - val_target_class_loss: 1.8563 - val_before_after_loss: 0.7307 - val_target_class_multi_acc: 0.4793 - val_before_after_single_acc: 0.5689\n",
            "Epoch 16/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.2651 - target_class_loss: 1.6599 - before_after_loss: 0.6052 - target_class_multi_acc: 0.5220 - before_after_single_acc: 0.6754\n",
            "Epoch 16: val_loss did not improve from 2.49332\n",
            "100/100 [==============================] - 16s 161ms/step - loss: 2.2651 - target_class_loss: 1.6599 - before_after_loss: 0.6052 - target_class_multi_acc: 0.5220 - before_after_single_acc: 0.6754 - val_loss: 2.6725 - val_target_class_loss: 1.9180 - val_before_after_loss: 0.7545 - val_target_class_multi_acc: 0.4867 - val_before_after_single_acc: 0.5809\n",
            "Epoch 17/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.2922 - target_class_loss: 1.6915 - before_after_loss: 0.6007 - target_class_multi_acc: 0.5225 - before_after_single_acc: 0.6780\n",
            "Epoch 17: val_loss did not improve from 2.49332\n",
            "100/100 [==============================] - 15s 154ms/step - loss: 2.2922 - target_class_loss: 1.6915 - before_after_loss: 0.6007 - target_class_multi_acc: 0.5225 - before_after_single_acc: 0.6780 - val_loss: 3.1569 - val_target_class_loss: 2.1017 - val_before_after_loss: 1.0552 - val_target_class_multi_acc: 0.3111 - val_before_after_single_acc: 0.4945\n",
            "Epoch 18/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.2747 - target_class_loss: 1.6775 - before_after_loss: 0.5972 - target_class_multi_acc: 0.5301 - before_after_single_acc: 0.6797\n",
            "Epoch 18: val_loss did not improve from 2.49332\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 2.2747 - target_class_loss: 1.6775 - before_after_loss: 0.5972 - target_class_multi_acc: 0.5301 - before_after_single_acc: 0.6797 - val_loss: 4.0851 - val_target_class_loss: 2.6025 - val_before_after_loss: 1.4826 - val_target_class_multi_acc: 0.5119 - val_before_after_single_acc: 0.5115\n",
            "Epoch 19/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.3149 - target_class_loss: 1.7164 - before_after_loss: 0.5985 - target_class_multi_acc: 0.5152 - before_after_single_acc: 0.6835\n",
            "Epoch 19: val_loss did not improve from 2.49332\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 2.3149 - target_class_loss: 1.7164 - before_after_loss: 0.5985 - target_class_multi_acc: 0.5152 - before_after_single_acc: 0.6835 - val_loss: 2.5771 - val_target_class_loss: 1.8558 - val_before_after_loss: 0.7212 - val_target_class_multi_acc: 0.5087 - val_before_after_single_acc: 0.5993\n",
            "Epoch 20/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.2352 - target_class_loss: 1.6485 - before_after_loss: 0.5867 - target_class_multi_acc: 0.5366 - before_after_single_acc: 0.6876\n",
            "Epoch 20: val_loss did not improve from 2.49332\n",
            "100/100 [==============================] - 16s 155ms/step - loss: 2.2352 - target_class_loss: 1.6485 - before_after_loss: 0.5867 - target_class_multi_acc: 0.5366 - before_after_single_acc: 0.6876 - val_loss: 2.6673 - val_target_class_loss: 1.8681 - val_before_after_loss: 0.7992 - val_target_class_multi_acc: 0.4301 - val_before_after_single_acc: 0.5478\n",
            "Epoch 21/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.2061 - target_class_loss: 1.6228 - before_after_loss: 0.5833 - target_class_multi_acc: 0.5326 - before_after_single_acc: 0.6954\n",
            "Epoch 21: val_loss did not improve from 2.49332\n",
            "100/100 [==============================] - 15s 155ms/step - loss: 2.2061 - target_class_loss: 1.6228 - before_after_loss: 0.5833 - target_class_multi_acc: 0.5326 - before_after_single_acc: 0.6954 - val_loss: 6.9682 - val_target_class_loss: 4.0797 - val_before_after_loss: 2.8885 - val_target_class_multi_acc: 0.4986 - val_before_after_single_acc: 0.5175\n",
            "Epoch 22/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.2602 - target_class_loss: 1.6740 - before_after_loss: 0.5862 - target_class_multi_acc: 0.5283 - before_after_single_acc: 0.6932\n",
            "Epoch 22: val_loss did not improve from 2.49332\n",
            "100/100 [==============================] - 15s 153ms/step - loss: 2.2602 - target_class_loss: 1.6740 - before_after_loss: 0.5862 - target_class_multi_acc: 0.5283 - before_after_single_acc: 0.6932 - val_loss: 5.9758 - val_target_class_loss: 3.4858 - val_before_after_loss: 2.4900 - val_target_class_multi_acc: 0.2192 - val_before_after_single_acc: 0.4926\n",
            "Epoch 23/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.2292 - target_class_loss: 1.6483 - before_after_loss: 0.5809 - target_class_multi_acc: 0.5391 - before_after_single_acc: 0.6995\n",
            "Epoch 23: val_loss improved from 2.49332 to 2.47846, saving model to best.h5\n",
            "100/100 [==============================] - 16s 160ms/step - loss: 2.2292 - target_class_loss: 1.6483 - before_after_loss: 0.5809 - target_class_multi_acc: 0.5391 - before_after_single_acc: 0.6995 - val_loss: 2.4785 - val_target_class_loss: 1.7690 - val_before_after_loss: 0.7094 - val_target_class_multi_acc: 0.4761 - val_before_after_single_acc: 0.6071\n",
            "Epoch 24/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.2687 - target_class_loss: 1.6859 - before_after_loss: 0.5828 - target_class_multi_acc: 0.5231 - before_after_single_acc: 0.6962\n",
            "Epoch 24: val_loss did not improve from 2.47846\n",
            "100/100 [==============================] - 16s 155ms/step - loss: 2.2687 - target_class_loss: 1.6859 - before_after_loss: 0.5828 - target_class_multi_acc: 0.5231 - before_after_single_acc: 0.6962 - val_loss: 3.1235 - val_target_class_loss: 2.1854 - val_before_after_loss: 0.9382 - val_target_class_multi_acc: 0.4931 - val_before_after_single_acc: 0.5754\n",
            "Epoch 25/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.1950 - target_class_loss: 1.6254 - before_after_loss: 0.5696 - target_class_multi_acc: 0.5446 - before_after_single_acc: 0.7068\n",
            "Epoch 25: val_loss did not improve from 2.47846\n",
            "100/100 [==============================] - 15s 154ms/step - loss: 2.1950 - target_class_loss: 1.6254 - before_after_loss: 0.5696 - target_class_multi_acc: 0.5446 - before_after_single_acc: 0.7068 - val_loss: 2.5571 - val_target_class_loss: 1.7884 - val_before_after_loss: 0.7687 - val_target_class_multi_acc: 0.5097 - val_before_after_single_acc: 0.5689\n",
            "Epoch 26/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.1796 - target_class_loss: 1.6073 - before_after_loss: 0.5723 - target_class_multi_acc: 0.5386 - before_after_single_acc: 0.7011\n",
            "Epoch 26: val_loss improved from 2.47846 to 2.38968, saving model to best.h5\n",
            "100/100 [==============================] - 16s 159ms/step - loss: 2.1796 - target_class_loss: 1.6073 - before_after_loss: 0.5723 - target_class_multi_acc: 0.5386 - before_after_single_acc: 0.7011 - val_loss: 2.3897 - val_target_class_loss: 1.7355 - val_before_after_loss: 0.6541 - val_target_class_multi_acc: 0.5253 - val_before_after_single_acc: 0.6392\n",
            "Epoch 27/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.2303 - target_class_loss: 1.6537 - before_after_loss: 0.5766 - target_class_multi_acc: 0.5346 - before_after_single_acc: 0.6974\n",
            "Epoch 27: val_loss did not improve from 2.38968\n",
            "100/100 [==============================] - 15s 154ms/step - loss: 2.2303 - target_class_loss: 1.6537 - before_after_loss: 0.5766 - target_class_multi_acc: 0.5346 - before_after_single_acc: 0.6974 - val_loss: 2.5541 - val_target_class_loss: 1.7962 - val_before_after_loss: 0.7579 - val_target_class_multi_acc: 0.5055 - val_before_after_single_acc: 0.6337\n",
            "Epoch 28/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.2134 - target_class_loss: 1.6400 - before_after_loss: 0.5734 - target_class_multi_acc: 0.5384 - before_after_single_acc: 0.7080\n",
            "Epoch 28: val_loss did not improve from 2.38968\n",
            "100/100 [==============================] - 16s 155ms/step - loss: 2.2134 - target_class_loss: 1.6400 - before_after_loss: 0.5734 - target_class_multi_acc: 0.5384 - before_after_single_acc: 0.7080 - val_loss: 2.5503 - val_target_class_loss: 1.8560 - val_before_after_loss: 0.6942 - val_target_class_multi_acc: 0.4508 - val_before_after_single_acc: 0.6383\n",
            "Epoch 29/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.2320 - target_class_loss: 1.6614 - before_after_loss: 0.5706 - target_class_multi_acc: 0.5281 - before_after_single_acc: 0.7070\n",
            "Epoch 29: val_loss did not improve from 2.38968\n",
            "100/100 [==============================] - 16s 155ms/step - loss: 2.2320 - target_class_loss: 1.6614 - before_after_loss: 0.5706 - target_class_multi_acc: 0.5281 - before_after_single_acc: 0.7070 - val_loss: 2.7295 - val_target_class_loss: 1.9086 - val_before_after_loss: 0.8210 - val_target_class_multi_acc: 0.3355 - val_before_after_single_acc: 0.5184\n",
            "Epoch 30/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.1730 - target_class_loss: 1.6100 - before_after_loss: 0.5629 - target_class_multi_acc: 0.5459 - before_after_single_acc: 0.7119\n",
            "Epoch 30: val_loss did not improve from 2.38968\n",
            "100/100 [==============================] - 16s 160ms/step - loss: 2.1730 - target_class_loss: 1.6100 - before_after_loss: 0.5629 - target_class_multi_acc: 0.5459 - before_after_single_acc: 0.7119 - val_loss: 2.7148 - val_target_class_loss: 1.9185 - val_before_after_loss: 0.7963 - val_target_class_multi_acc: 0.4522 - val_before_after_single_acc: 0.6144\n",
            "Epoch 31/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.1473 - target_class_loss: 1.5844 - before_after_loss: 0.5628 - target_class_multi_acc: 0.5413 - before_after_single_acc: 0.7180\n",
            "Epoch 31: val_loss did not improve from 2.38968\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 2.1473 - target_class_loss: 1.5844 - before_after_loss: 0.5628 - target_class_multi_acc: 0.5413 - before_after_single_acc: 0.7180 - val_loss: 2.9355 - val_target_class_loss: 2.0365 - val_before_after_loss: 0.8990 - val_target_class_multi_acc: 0.5018 - val_before_after_single_acc: 0.5786\n",
            "Epoch 32/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.2064 - target_class_loss: 1.6364 - before_after_loss: 0.5700 - target_class_multi_acc: 0.5362 - before_after_single_acc: 0.7078\n",
            "Epoch 32: val_loss improved from 2.38968 to 2.38782, saving model to best.h5\n",
            "100/100 [==============================] - 16s 160ms/step - loss: 2.2064 - target_class_loss: 1.6364 - before_after_loss: 0.5700 - target_class_multi_acc: 0.5362 - before_after_single_acc: 0.7078 - val_loss: 2.3878 - val_target_class_loss: 1.7422 - val_before_after_loss: 0.6456 - val_target_class_multi_acc: 0.5175 - val_before_after_single_acc: 0.6415\n",
            "Epoch 33/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.1656 - target_class_loss: 1.6076 - before_after_loss: 0.5579 - target_class_multi_acc: 0.5479 - before_after_single_acc: 0.7177\n",
            "Epoch 33: val_loss did not improve from 2.38782\n",
            "100/100 [==============================] - 15s 155ms/step - loss: 2.1656 - target_class_loss: 1.6076 - before_after_loss: 0.5579 - target_class_multi_acc: 0.5479 - before_after_single_acc: 0.7177 - val_loss: 4.0753 - val_target_class_loss: 2.6065 - val_before_after_loss: 1.4688 - val_target_class_multi_acc: 0.3828 - val_before_after_single_acc: 0.5988\n",
            "Epoch 34/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.2084 - target_class_loss: 1.6457 - before_after_loss: 0.5627 - target_class_multi_acc: 0.5306 - before_after_single_acc: 0.7138\n",
            "Epoch 34: val_loss did not improve from 2.38782\n",
            "100/100 [==============================] - 16s 158ms/step - loss: 2.2084 - target_class_loss: 1.6457 - before_after_loss: 0.5627 - target_class_multi_acc: 0.5306 - before_after_single_acc: 0.7138 - val_loss: 2.9202 - val_target_class_loss: 2.0015 - val_before_after_loss: 0.9187 - val_target_class_multi_acc: 0.3704 - val_before_after_single_acc: 0.5643\n",
            "Epoch 35/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.1421 - target_class_loss: 1.5865 - before_after_loss: 0.5556 - target_class_multi_acc: 0.5487 - before_after_single_acc: 0.7172\n",
            "Epoch 35: val_loss did not improve from 2.38782\n",
            "100/100 [==============================] - 16s 164ms/step - loss: 2.1421 - target_class_loss: 1.5865 - before_after_loss: 0.5556 - target_class_multi_acc: 0.5487 - before_after_single_acc: 0.7172 - val_loss: 2.5704 - val_target_class_loss: 1.8441 - val_before_after_loss: 0.7264 - val_target_class_multi_acc: 0.4678 - val_before_after_single_acc: 0.5956\n",
            "Epoch 36/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.1314 - target_class_loss: 1.5769 - before_after_loss: 0.5545 - target_class_multi_acc: 0.5419 - before_after_single_acc: 0.7230\n",
            "Epoch 36: val_loss did not improve from 2.38782\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 2.1314 - target_class_loss: 1.5769 - before_after_loss: 0.5545 - target_class_multi_acc: 0.5419 - before_after_single_acc: 0.7230 - val_loss: 2.5420 - val_target_class_loss: 1.8201 - val_before_after_loss: 0.7219 - val_target_class_multi_acc: 0.5110 - val_before_after_single_acc: 0.6314\n",
            "Epoch 37/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.1648 - target_class_loss: 1.6110 - before_after_loss: 0.5538 - target_class_multi_acc: 0.5359 - before_after_single_acc: 0.7212\n",
            "Epoch 37: val_loss did not improve from 2.38782\n",
            "100/100 [==============================] - 16s 158ms/step - loss: 2.1648 - target_class_loss: 1.6110 - before_after_loss: 0.5538 - target_class_multi_acc: 0.5359 - before_after_single_acc: 0.7212 - val_loss: 3.9447 - val_target_class_loss: 2.5696 - val_before_after_loss: 1.3751 - val_target_class_multi_acc: 0.5147 - val_before_after_single_acc: 0.5800\n",
            "Epoch 38/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.1344 - target_class_loss: 1.5853 - before_after_loss: 0.5491 - target_class_multi_acc: 0.5519 - before_after_single_acc: 0.7218\n",
            "Epoch 38: val_loss did not improve from 2.38782\n",
            "100/100 [==============================] - 15s 154ms/step - loss: 2.1344 - target_class_loss: 1.5853 - before_after_loss: 0.5491 - target_class_multi_acc: 0.5519 - before_after_single_acc: 0.7218 - val_loss: 2.9354 - val_target_class_loss: 1.9666 - val_before_after_loss: 0.9688 - val_target_class_multi_acc: 0.5193 - val_before_after_single_acc: 0.5574\n",
            "Epoch 39/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.1873 - target_class_loss: 1.6311 - before_after_loss: 0.5562 - target_class_multi_acc: 0.5331 - before_after_single_acc: 0.7180\n",
            "Epoch 39: val_loss improved from 2.38782 to 2.31706, saving model to best.h5\n",
            "100/100 [==============================] - 16s 160ms/step - loss: 2.1873 - target_class_loss: 1.6311 - before_after_loss: 0.5562 - target_class_multi_acc: 0.5331 - before_after_single_acc: 0.7180 - val_loss: 2.3171 - val_target_class_loss: 1.6880 - val_before_after_loss: 0.6290 - val_target_class_multi_acc: 0.5037 - val_before_after_single_acc: 0.6687\n",
            "Epoch 40/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.1248 - target_class_loss: 1.5769 - before_after_loss: 0.5480 - target_class_multi_acc: 0.5467 - before_after_single_acc: 0.7277\n",
            "Epoch 40: val_loss did not improve from 2.31706\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 2.1248 - target_class_loss: 1.5769 - before_after_loss: 0.5480 - target_class_multi_acc: 0.5467 - before_after_single_acc: 0.7277 - val_loss: 2.8118 - val_target_class_loss: 1.9624 - val_before_after_loss: 0.8494 - val_target_class_multi_acc: 0.5037 - val_before_after_single_acc: 0.6006\n",
            "Epoch 41/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.1031 - target_class_loss: 1.5571 - before_after_loss: 0.5460 - target_class_multi_acc: 0.5489 - before_after_single_acc: 0.7235\n",
            "Epoch 41: val_loss did not improve from 2.31706\n",
            "100/100 [==============================] - 15s 155ms/step - loss: 2.1031 - target_class_loss: 1.5571 - before_after_loss: 0.5460 - target_class_multi_acc: 0.5489 - before_after_single_acc: 0.7235 - val_loss: 2.9121 - val_target_class_loss: 1.9920 - val_before_after_loss: 0.9201 - val_target_class_multi_acc: 0.4766 - val_before_after_single_acc: 0.6176\n",
            "Epoch 42/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.1477 - target_class_loss: 1.5998 - before_after_loss: 0.5479 - target_class_multi_acc: 0.5383 - before_after_single_acc: 0.7240\n",
            "Epoch 42: val_loss did not improve from 2.31706\n",
            "100/100 [==============================] - 15s 154ms/step - loss: 2.1477 - target_class_loss: 1.5998 - before_after_loss: 0.5479 - target_class_multi_acc: 0.5383 - before_after_single_acc: 0.7240 - val_loss: 2.4414 - val_target_class_loss: 1.7318 - val_before_after_loss: 0.7095 - val_target_class_multi_acc: 0.5028 - val_before_after_single_acc: 0.5882\n",
            "Epoch 43/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.1128 - target_class_loss: 1.5712 - before_after_loss: 0.5416 - target_class_multi_acc: 0.5556 - before_after_single_acc: 0.7323\n",
            "Epoch 43: val_loss did not improve from 2.31706\n",
            "100/100 [==============================] - 15s 154ms/step - loss: 2.1128 - target_class_loss: 1.5712 - before_after_loss: 0.5416 - target_class_multi_acc: 0.5556 - before_after_single_acc: 0.7323 - val_loss: 3.6935 - val_target_class_loss: 2.3855 - val_before_after_loss: 1.3080 - val_target_class_multi_acc: 0.2849 - val_before_after_single_acc: 0.5083\n",
            "Epoch 44/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.1607 - target_class_loss: 1.6163 - before_after_loss: 0.5444 - target_class_multi_acc: 0.5316 - before_after_single_acc: 0.7244\n",
            "Epoch 44: val_loss did not improve from 2.31706\n",
            "100/100 [==============================] - 16s 164ms/step - loss: 2.1607 - target_class_loss: 1.6163 - before_after_loss: 0.5444 - target_class_multi_acc: 0.5316 - before_after_single_acc: 0.7244 - val_loss: 2.5295 - val_target_class_loss: 1.7798 - val_before_after_loss: 0.7498 - val_target_class_multi_acc: 0.4940 - val_before_after_single_acc: 0.6140\n",
            "Epoch 45/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.0915 - target_class_loss: 1.5544 - before_after_loss: 0.5371 - target_class_multi_acc: 0.5530 - before_after_single_acc: 0.7368\n",
            "Epoch 45: val_loss did not improve from 2.31706\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 2.0915 - target_class_loss: 1.5544 - before_after_loss: 0.5371 - target_class_multi_acc: 0.5530 - before_after_single_acc: 0.7368 - val_loss: 2.3753 - val_target_class_loss: 1.7446 - val_before_after_loss: 0.6307 - val_target_class_multi_acc: 0.5221 - val_before_after_single_acc: 0.6521\n",
            "Epoch 46/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.0808 - target_class_loss: 1.5469 - before_after_loss: 0.5338 - target_class_multi_acc: 0.5516 - before_after_single_acc: 0.7351\n",
            "Epoch 46: val_loss did not improve from 2.31706\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 2.0808 - target_class_loss: 1.5469 - before_after_loss: 0.5338 - target_class_multi_acc: 0.5516 - before_after_single_acc: 0.7351 - val_loss: 2.4487 - val_target_class_loss: 1.7893 - val_before_after_loss: 0.6594 - val_target_class_multi_acc: 0.5101 - val_before_after_single_acc: 0.6494\n",
            "Epoch 47/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.1192 - target_class_loss: 1.5806 - before_after_loss: 0.5386 - target_class_multi_acc: 0.5411 - before_after_single_acc: 0.7330\n",
            "Epoch 47: val_loss did not improve from 2.31706\n",
            "100/100 [==============================] - 16s 155ms/step - loss: 2.1192 - target_class_loss: 1.5806 - before_after_loss: 0.5386 - target_class_multi_acc: 0.5411 - before_after_single_acc: 0.7330 - val_loss: 2.5443 - val_target_class_loss: 1.8310 - val_before_after_loss: 0.7133 - val_target_class_multi_acc: 0.4651 - val_before_after_single_acc: 0.5800\n",
            "Epoch 48/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.0678 - target_class_loss: 1.5434 - before_after_loss: 0.5244 - target_class_multi_acc: 0.5567 - before_after_single_acc: 0.7409\n",
            "Epoch 48: val_loss did not improve from 2.31706\n",
            "100/100 [==============================] - 15s 154ms/step - loss: 2.0678 - target_class_loss: 1.5434 - before_after_loss: 0.5244 - target_class_multi_acc: 0.5567 - before_after_single_acc: 0.7409 - val_loss: 2.5098 - val_target_class_loss: 1.7936 - val_before_after_loss: 0.7162 - val_target_class_multi_acc: 0.5142 - val_before_after_single_acc: 0.6287\n",
            "Epoch 49/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.1185 - target_class_loss: 1.5857 - before_after_loss: 0.5329 - target_class_multi_acc: 0.5386 - before_after_single_acc: 0.7349\n",
            "Epoch 49: val_loss did not improve from 2.31706\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 2.1185 - target_class_loss: 1.5857 - before_after_loss: 0.5329 - target_class_multi_acc: 0.5386 - before_after_single_acc: 0.7349 - val_loss: 2.3749 - val_target_class_loss: 1.7128 - val_before_after_loss: 0.6620 - val_target_class_multi_acc: 0.5138 - val_before_after_single_acc: 0.6618\n",
            "Epoch 50/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.0629 - target_class_loss: 1.5407 - before_after_loss: 0.5221 - target_class_multi_acc: 0.5573 - before_after_single_acc: 0.7377\n",
            "Epoch 50: val_loss did not improve from 2.31706\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 2.0629 - target_class_loss: 1.5407 - before_after_loss: 0.5221 - target_class_multi_acc: 0.5573 - before_after_single_acc: 0.7377 - val_loss: 2.4867 - val_target_class_loss: 1.7964 - val_before_after_loss: 0.6903 - val_target_class_multi_acc: 0.5165 - val_before_after_single_acc: 0.6581\n",
            "Epoch 51/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.0512 - target_class_loss: 1.5281 - before_after_loss: 0.5231 - target_class_multi_acc: 0.5546 - before_after_single_acc: 0.7452\n",
            "Epoch 51: val_loss did not improve from 2.31706\n",
            "100/100 [==============================] - 16s 155ms/step - loss: 2.0512 - target_class_loss: 1.5281 - before_after_loss: 0.5231 - target_class_multi_acc: 0.5546 - before_after_single_acc: 0.7452 - val_loss: 2.6851 - val_target_class_loss: 1.8835 - val_before_after_loss: 0.8016 - val_target_class_multi_acc: 0.5244 - val_before_after_single_acc: 0.6039\n",
            "Epoch 52/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.0860 - target_class_loss: 1.5622 - before_after_loss: 0.5238 - target_class_multi_acc: 0.5475 - before_after_single_acc: 0.7402\n",
            "Epoch 52: val_loss did not improve from 2.31706\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 2.0860 - target_class_loss: 1.5622 - before_after_loss: 0.5238 - target_class_multi_acc: 0.5475 - before_after_single_acc: 0.7402 - val_loss: 3.3151 - val_target_class_loss: 2.2133 - val_before_after_loss: 1.1018 - val_target_class_multi_acc: 0.5000 - val_before_after_single_acc: 0.6144\n",
            "Epoch 53/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.0366 - target_class_loss: 1.5235 - before_after_loss: 0.5131 - target_class_multi_acc: 0.5655 - before_after_single_acc: 0.7498"
          ]
        }
      ],
      "source": [
        "model_name = 'ITIME_BOTH'\n",
        "# model_name = 'CONVMHSA_BOTH'\n",
        "save_path = ''\n",
        "\n",
        "        \n",
        "flight_res = []\n",
        "\n",
        "\n",
        "for fold in tqdm(range(5)): \n",
        "\n",
        "    save_filename = save_path + '%s_%i' % (model_name, fold)\n",
        "    \n",
        "\n",
        "    train_ds = dm.get_tf_dataset(fold = fold, training = True, shuffle = 1000, repeat = True, mode = mode, batch_size = 128)\n",
        "    test_ds = dm.get_tf_dataset(fold = fold, training  = False, shuffle = False, repeat = False, mode = mode, batch_size = 128)\n",
        "\n",
        "\n",
        "    with strategy.scope():\n",
        "        model = Classifier_INCEPTION(input_shape = (4096, 23), nb_classes=nb_classes, two_output = two_output ).model\n",
        "        lr = 1e-4\n",
        "\n",
        "        # model = get_mhsa_model(nbclass=nb_classes, mode = mode)\n",
        "        # lr = 3e-5\n",
        "\n",
        "        if two_output: \n",
        "                        \n",
        "            model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=lr),\n",
        "                        metrics = \n",
        "                                    {'target_class' : [tf.keras.metrics.SparseCategoricalAccuracy(name = 'multi_acc')],\n",
        "                                    'before_after' : [tf.keras.metrics.BinaryAccuracy(name = 'single_acc')],\n",
        "                                    }\n",
        "\n",
        "                        , \n",
        "                        loss = {'target_class' : tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False, name = 'multi_loss'),\n",
        "                                'before_after' : tf.keras.losses.BinaryCrossentropy(from_logits=False, name = 'single_loss')}\n",
        "            )\n",
        "\n",
        "\n",
        "        elif mode == 'before_after':\n",
        "                \n",
        "            model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=lr),\n",
        "                        metrics = [\n",
        "                                    tf.keras.metrics.BinaryAccuracy()\n",
        "                        ], \n",
        "                        loss = tf.keras.losses.BinaryCrossentropy(from_logits=False))\n",
        "\n",
        "\n",
        "        elif mode == 'classes':\n",
        "                \n",
        "            model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=lr),\n",
        "                        metrics = [\n",
        "                                    tf.keras.metrics.SparseCategoricalAccuracy(name = 'multi_acc')\n",
        "                        ], \n",
        "                        loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False))\n",
        "            \n",
        "        else:\n",
        "            raise \n",
        "       \n",
        "\n",
        "        callbacks = [\n",
        "                tf.keras.callbacks.ModelCheckpoint(\n",
        "                    filepath=\"best.h5\",\n",
        "                    save_best_only=True,  # Only save a model if `val_loss` has improved.\n",
        "                    monitor=\"val_loss\",\n",
        "                    verbose=1,\n",
        "                    save_weights_only=True\n",
        "                )\n",
        "            ]\n",
        "\n",
        "\n",
        "        history = model.fit(\n",
        "            train_ds,\n",
        "            steps_per_epoch = 100, \n",
        "            epochs = 200, \n",
        "            validation_data = test_ds,\n",
        "            callbacks = callbacks,\n",
        "            verbose = True, \n",
        "\n",
        "        )\n",
        "\n",
        "        history = pd.DataFrame(history.history)\n",
        "        history['epoch'] = history.index\n",
        "        history['model'] = model_name\n",
        "        history.to_csv(save_filename)\n",
        "\n",
        "        model.load_weights('best.h5')\n",
        "\n",
        "\n",
        "        flights_before_acc = {}\n",
        "\n",
        "        for day in range(5):\n",
        "                \n",
        "\n",
        "            indices = list(dm.flight_header_df[ (dm.flight_header_df['number_flights_before'] == day) & (dm.flight_header_df.before_after == 1) & (dm.flight_header_df.fold == fold) & (dm.flight_header_df.label == 'intake gasket leak/damage')].index)\n",
        "            print(len(indices))\n",
        "            ds = tf.data.Dataset.from_tensor_slices(to_dict_of_list([example for example in dm.data_dict if example['id'] in indices]))\n",
        "\n",
        "            ds = dm.get_tf_dataset(ds = ds , fold = 0, training  = False, shuffle = False, repeat = False, mode = mode, batch_size = 2)\n",
        "            \n",
        "            res = model.evaluate(ds)\n",
        "\n",
        "            flights_before_acc[day] = res[-1]\n",
        "            \n",
        "        flight_res.append(flights_before_acc)\n",
        "        \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qfotnkc8cMd8"
      },
      "outputs": [],
      "source": [
        "flight_res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nDMVQso0W-WI"
      },
      "outputs": [],
      "source": [
        "print(flight_res)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [
        "9NBLjv7UgsWd"
      ],
      "name": "NGAFID DATASET TF EXAMPLE.ipynb",
      "provenance": [],
      "mount_file_id": "1SidmvHoUH0H4Ez8BzG-2Wyrjwbs8lxit",
      "authorship_tag": "ABX9TyO9DoG3AtN0qwyoXNv6DzIR",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ae033449ece34336b16b1b8c70f29a0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_41b6364e3504485c9a1d77d70a85d33d",
              "IPY_MODEL_8f48831840a94ac0acf6aef995f623d5",
              "IPY_MODEL_d47c18b3d8174f7b910ad24985e645a9"
            ],
            "layout": "IPY_MODEL_56f2e7e88f204e8080bc854e906795f3"
          }
        },
        "41b6364e3504485c9a1d77d70a85d33d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d87d336ce104c5e8508e808fe470614",
            "placeholder": "​",
            "style": "IPY_MODEL_3a91db044fa24d7f89803b86bc51c054",
            "value": "100%"
          }
        },
        "8f48831840a94ac0acf6aef995f623d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec848bdd788c492eb95b7facf799df07",
            "max": 11446,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_73eed9dd178d4e389ea79e30a9385c2b",
            "value": 11446
          }
        },
        "d47c18b3d8174f7b910ad24985e645a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_685d2977b2134c75bb4d741a25d364d5",
            "placeholder": "​",
            "style": "IPY_MODEL_4ad47b2f08bb437590f06c2b946946ef",
            "value": " 11446/11446 [00:41&lt;00:00, 324.76it/s]"
          }
        },
        "56f2e7e88f204e8080bc854e906795f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d87d336ce104c5e8508e808fe470614": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a91db044fa24d7f89803b86bc51c054": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec848bdd788c492eb95b7facf799df07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73eed9dd178d4e389ea79e30a9385c2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "685d2977b2134c75bb4d741a25d364d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ad47b2f08bb437590f06c2b946946ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b84580d7b4ef44fcaf590a92cb5f059e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1bc47cf3c19042eab2d18616f2f3ab26",
              "IPY_MODEL_47d14723b7f14229ba60e46177282af1",
              "IPY_MODEL_03d4dda7dd3140658b4de230426f7bdc"
            ],
            "layout": "IPY_MODEL_746381eea2f24aa6a8fc1eb0dcb79d77"
          }
        },
        "1bc47cf3c19042eab2d18616f2f3ab26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bbd1939f519f4179b47e775dd9373cd7",
            "placeholder": "​",
            "style": "IPY_MODEL_d2274730403c4592833c5c3177a39e20",
            "value": "  0%"
          }
        },
        "47d14723b7f14229ba60e46177282af1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_559c8ebd1c414b4e8e680598725d2423",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ddc0c360a6c140e6b532cae8b9624de0",
            "value": 0
          }
        },
        "03d4dda7dd3140658b4de230426f7bdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d40b7ad6b9024fe78fd7e39fe4b38e4d",
            "placeholder": "​",
            "style": "IPY_MODEL_df765d955633452eb649708b9d0eb54b",
            "value": " 0/5 [00:00&lt;?, ?it/s]"
          }
        },
        "746381eea2f24aa6a8fc1eb0dcb79d77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbd1939f519f4179b47e775dd9373cd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2274730403c4592833c5c3177a39e20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "559c8ebd1c414b4e8e680598725d2423": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddc0c360a6c140e6b532cae8b9624de0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d40b7ad6b9024fe78fd7e39fe4b38e4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df765d955633452eb649708b9d0eb54b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}